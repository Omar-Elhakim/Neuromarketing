{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d186a6b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-01T20:23:56.514590Z",
     "iopub.status.busy": "2025-12-01T20:23:56.513903Z",
     "iopub.status.idle": "2025-12-01T20:23:56.517617Z",
     "shell.execute_reply": "2025-12-01T20:23:56.517094Z"
    },
    "papermill": {
     "duration": 0.008818,
     "end_time": "2025-12-01T20:23:56.518714",
     "exception": false,
     "start_time": "2025-12-01T20:23:56.509896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a0ced7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:23:56.524222Z",
     "iopub.status.busy": "2025-12-01T20:23:56.523787Z",
     "iopub.status.idle": "2025-12-01T20:37:46.184100Z",
     "shell.execute_reply": "2025-12-01T20:37:46.183183Z"
    },
    "papermill": {
     "duration": 829.664574,
     "end_time": "2025-12-01T20:37:46.185688",
     "exception": false,
     "start_time": "2025-12-01T20:23:56.521114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torcheeg\r\n",
      "  Downloading torcheeg-1.1.3.tar.gz (251 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting torch-scatter\r\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (4.67.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.2.3)\r\n",
      "Requirement already satisfied: xlrd>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.0.2)\r\n",
      "Collecting scipy<=1.10.1,>=1.7.3 (from torcheeg)\r\n",
      "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.2.2)\r\n",
      "Collecting lmdb>=1.3.0 (from torcheeg)\r\n",
      "  Downloading lmdb-1.7.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: einops>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (0.8.1)\r\n",
      "Requirement already satisfied: mne>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.10.2)\r\n",
      "Collecting xmltodict>=0.13.0 (from torcheeg)\r\n",
      "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (3.5)\r\n",
      "Requirement already satisfied: PyWavelets>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.8.0)\r\n",
      "Collecting spectrum>=0.8.1 (from torcheeg)\r\n",
      "  Downloading spectrum-0.9.0.tar.gz (231 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torchmetrics>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.8.2)\r\n",
      "Collecting mne_connectivity>=0.4.0 (from torcheeg)\r\n",
      "  Downloading mne_connectivity-0.7.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: pytorch-lightning>=1.9.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.5.5)\r\n",
      "Collecting wfdb>=4.1.2 (from torcheeg)\r\n",
      "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.15.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (4.4.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (0.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (3.7.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (25.0)\r\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (1.8.2)\r\n",
      "INFO: pip is looking at multiple versions of mne to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting mne>=1.0.3 (from torcheeg)\r\n",
      "  Downloading mne-1.11.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting matplotlib>=3.8 (from mne>=1.0.3->torcheeg)\r\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting mne>=1.0.3 (from torcheeg)\r\n",
      "  Downloading mne-1.10.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "  Downloading mne-1.10.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting netCDF4>=1.6.5 (from mne_connectivity>=0.4.0->torcheeg)\r\n",
      "  Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: xarray>=2023.11.0 in /usr/local/lib/python3.11/dist-packages (from mne_connectivity>=0.4.0->torcheeg) (2025.7.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2025.2)\r\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (6.0.3)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (0.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->torcheeg) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->torcheeg) (3.6.0)\r\n",
      "Collecting easydev (from spectrum>=0.8.1->torcheeg)\r\n",
      "  Downloading easydev-0.13.3-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (3.13.2)\r\n",
      "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (2.32.5)\r\n",
      "INFO: pip is looking at multiple versions of wfdb to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting wfdb>=4.1.2 (from torcheeg)\r\n",
      "  Downloading wfdb-4.2.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (0.13.1)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.9.5->torcheeg) (75.2.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (3.0.9)\r\n",
      "Collecting cftime (from netCDF4>=1.6.5->mne_connectivity>=0.4.0->torcheeg)\r\n",
      "  Downloading cftime-1.6.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.6.5->mne_connectivity>=0.4.0->torcheeg) (2025.10.5)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (4.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->torcheeg) (1.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (2.5.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from SoundFile>=0.10.0->wfdb>=4.1.2->torcheeg) (2.0.0)\r\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (0.4.6)\r\n",
      "Requirement already satisfied: colorlog<7.0.0,>=6.8.2 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (6.10.1)\r\n",
      "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev->spectrum>=0.8.1->torcheeg)\r\n",
      "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\r\n",
      "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.9.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.5->torcheeg) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.5->torcheeg) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.5->torcheeg) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.5->torcheeg) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.5->torcheeg) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (1.22.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb>=4.1.2->torcheeg) (2.23)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.5->torcheeg) (2024.2.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lmdb-1.7.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (295 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.1/295.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mne-1.9.0-py3-none-any.whl (7.4 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mne_connectivity-0.7.0-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wfdb-4.1.2-py3-none-any.whl (159 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\r\n",
      "Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading easydev-0.13.3-py3-none-any.whl (57 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cftime-1.6.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: torcheeg, torch-scatter, spectrum\r\n",
      "  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for torcheeg: filename=torcheeg-1.1.3-py3-none-any.whl size=466286 sha256=2a7b2f0615d2badaecc55b26d3bb34ad6cb9a87d17dd5df74d192a09568d33aa\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/7e/e1/7004a323c223a4fce1b1c4b2c2afd8f608b4b5591a39008416\r\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3936074 sha256=fc1d45db4be9b816df5f7beafab95d3e037102323724c207dd41cd83487a283e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\r\n",
      "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for spectrum: filename=spectrum-0.9.0-cp311-cp311-linux_x86_64.whl size=236748 sha256=8e77216bdc7ef687a3e43430c102738d0cd7c337e48ffa89296c1143ceef9062\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/9c/de/eb558fbd03ea1540d3c908f23681f57f9d9e8c2a5cd08d6f42\r\n",
      "Successfully built torcheeg torch-scatter spectrum\r\n",
      "Installing collected packages: lmdb, xmltodict, torch-scatter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, line-profiler, nvidia-cusparse-cu12, nvidia-cudnn-cu12, easydev, nvidia-cusolver-cu12, scipy, cftime, netCDF4, mne, wfdb, spectrum, mne_connectivity, torcheeg\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: line-profiler\r\n",
      "    Found existing installation: line_profiler 5.0.0\r\n",
      "    Uninstalling line_profiler-5.0.0:\r\n",
      "      Successfully uninstalled line_profiler-5.0.0\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.3\r\n",
      "    Uninstalling scipy-1.15.3:\r\n",
      "      Successfully uninstalled scipy-1.15.3\r\n",
      "  Attempting uninstall: mne\r\n",
      "    Found existing installation: mne 1.10.2\r\n",
      "    Uninstalling mne-1.10.2:\r\n",
      "      Successfully uninstalled mne-1.10.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle-environments 1.18.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed cftime-1.6.5 easydev-0.13.3 line-profiler-4.2.0 lmdb-1.7.5 mne-1.9.0 mne_connectivity-0.7.0 netCDF4-1.7.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 scipy-1.10.1 spectrum-0.9.0 torch-scatter-2.1.2 torcheeg-1.1.3 wfdb-4.1.2 xmltodict-1.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheeg torch-scatter torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1499d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:37:46.231266Z",
     "iopub.status.busy": "2025-12-01T20:37:46.231002Z",
     "iopub.status.idle": "2025-12-01T20:37:58.416827Z",
     "shell.execute_reply": "2025-12-01T20:37:58.415649Z"
    },
    "papermill": {
     "duration": 12.210421,
     "end_time": "2025-12-01T20:37:58.418598",
     "exception": false,
     "start_time": "2025-12-01T20:37:46.208177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torcheeg.datasets import SEEDIVDataset\n",
    "from torcheeg import transforms\n",
    "# from torcheeg.models import EEGNet\n",
    "import scipy.signal as signal\n",
    "import random\n",
    "from torchvision.models import googlenet\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95448643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:37:58.474576Z",
     "iopub.status.busy": "2025-12-01T20:37:58.473683Z",
     "iopub.status.idle": "2025-12-01T20:37:58.505729Z",
     "shell.execute_reply": "2025-12-01T20:37:58.505195Z"
    },
    "papermill": {
     "duration": 0.057002,
     "end_time": "2025-12-01T20:37:58.506767",
     "exception": false,
     "start_time": "2025-12-01T20:37:58.449765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5356a4cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:37:58.553582Z",
     "iopub.status.busy": "2025-12-01T20:37:58.553356Z",
     "iopub.status.idle": "2025-12-01T20:37:58.556977Z",
     "shell.execute_reply": "2025-12-01T20:37:58.556447Z"
    },
    "papermill": {
     "duration": 0.028866,
     "end_time": "2025-12-01T20:37:58.558039",
     "exception": false,
     "start_time": "2025-12-01T20:37:58.529173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BandPassFilter(eeg_data):\n",
    "    b, a = signal.butter(4, Wn=[1.0, 75.0], btype='bandpass', fs=200)\n",
    "    return signal.filtfilt(b, a, eeg_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e870c87b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:37:58.602775Z",
     "iopub.status.busy": "2025-12-01T20:37:58.602574Z",
     "iopub.status.idle": "2025-12-01T20:37:58.606215Z",
     "shell.execute_reply": "2025-12-01T20:37:58.605532Z"
    },
    "papermill": {
     "duration": 0.027167,
     "end_time": "2025-12-01T20:37:58.607236",
     "exception": false,
     "start_time": "2025-12-01T20:37:58.580069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Notch(eeg_data):\n",
    "    b, a = signal.iirnotch(w0=50.0, Q=30.0, fs=200)\n",
    "    return signal.filtfilt(b, a, eeg_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32515bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:37:58.653228Z",
     "iopub.status.busy": "2025-12-01T20:37:58.652997Z",
     "iopub.status.idle": "2025-12-01T20:37:58.656282Z",
     "shell.execute_reply": "2025-12-01T20:37:58.655757Z"
    },
    "papermill": {
     "duration": 0.026887,
     "end_time": "2025-12-01T20:37:58.657243",
     "exception": false,
     "start_time": "2025-12-01T20:37:58.630356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Define Preprocessing\n",
    "t_transform = transforms.Compose([\n",
    "    transforms.Lambda(BandPassFilter),\n",
    "    # transforms.Lambda(Notch),\n",
    "    transforms.BaselineRemoval(),\n",
    "    transforms.MeanStdNormalize(),\n",
    "    transforms.To2d()\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6e1ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:37:58.703541Z",
     "iopub.status.busy": "2025-12-01T20:37:58.703318Z",
     "iopub.status.idle": "2025-12-01T20:41:25.271462Z",
     "shell.execute_reply": "2025-12-01T20:41:25.270815Z"
    },
    "papermill": {
     "duration": 206.592409,
     "end_time": "2025-12-01T20:41:25.272744",
     "exception": false,
     "start_time": "2025-12-01T20:37:58.680335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-01 20:37:58] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m./tmp_out/seed_iv\u001b[0m.\n",
      "[2025-12-01 20:37:58] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]:   0%|          | 0/45 [00:00<?, ?it/s]\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 1it [00:04,  4.86s/it]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 8it [00:04,  2.19it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 15it [00:05,  4.82it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 22it [00:05,  8.23it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 30it [00:05, 13.17it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 38it [00:05, 19.00it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 45it [00:05, 24.38it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 52it [00:05, 30.62it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 59it [00:05, 36.12it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 66it [00:05, 41.99it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 73it [00:05, 47.16it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 81it [00:06, 53.17it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 88it [00:06, 54.85it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 95it [00:06, 56.50it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 102it [00:06, 58.62it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 109it [00:06, 61.32it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 116it [00:06, 59.74it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 123it [00:06, 61.19it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 130it [00:06, 61.77it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 137it [00:06, 62.75it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 144it [00:07, 62.27it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 151it [00:07, 63.36it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 158it [00:07, 62.21it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 165it [00:07, 63.66it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 172it [00:07, 62.62it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 179it [00:07, 63.80it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 187it [00:07, 66.09it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 194it [00:07, 67.10it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 201it [00:07, 66.79it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 208it [00:08, 67.58it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 215it [00:08, 66.63it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 222it [00:08, 66.07it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 229it [00:08, 66.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 236it [00:08, 66.89it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 243it [00:08, 67.39it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 250it [00:08, 65.13it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 257it [00:08, 63.39it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 264it [00:08, 64.32it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 271it [00:09, 65.20it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 278it [00:09, 65.69it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 286it [00:09, 67.93it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 293it [00:09, 66.27it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 300it [00:09, 66.75it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 308it [00:09, 68.23it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 316it [00:09, 68.84it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 323it [00:09, 67.73it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 331it [00:10, 46.77it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 338it [00:10, 51.25it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 346it [00:10, 56.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 353it [00:10, 58.85it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 361it [00:10, 63.02it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 368it [00:10, 64.27it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 375it [00:10, 65.71it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 382it [00:10, 65.98it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 389it [00:10, 64.46it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 396it [00:11, 65.90it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 404it [00:11, 67.83it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 412it [00:11, 67.77it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 419it [00:11, 67.04it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 426it [00:11, 66.12it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 433it [00:11, 66.12it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 441it [00:11, 67.43it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 448it [00:11, 66.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 455it [00:11, 67.01it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 463it [00:11, 69.08it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 470it [00:12, 67.25it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 478it [00:12, 68.19it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 485it [00:12, 67.00it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 492it [00:12, 66.46it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 500it [00:12, 67.96it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 507it [00:12, 67.41it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 514it [00:12, 67.21it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 521it [00:12, 65.80it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 528it [00:12, 66.96it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 535it [00:13, 67.05it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 542it [00:13, 67.47it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 550it [00:13, 69.47it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 557it [00:13, 68.70it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 564it [00:13, 68.39it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 572it [00:13, 69.68it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 579it [00:13, 66.57it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 586it [00:13, 63.42it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 593it [00:13, 64.46it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 600it [00:14, 66.00it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 607it [00:14, 65.41it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 614it [00:14, 65.96it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 621it [00:14, 62.75it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 628it [00:14, 63.15it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 635it [00:14, 63.42it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 642it [00:14, 64.94it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 649it [00:14, 64.60it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 656it [00:14, 65.71it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 664it [00:15, 67.25it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 671it [00:15, 66.41it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 678it [00:15, 67.36it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 685it [00:15, 67.47it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 692it [00:15, 66.20it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 699it [00:15, 63.98it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 706it [00:15, 63.67it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 713it [00:15, 63.00it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 720it [00:15, 64.03it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 727it [00:16, 63.96it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 734it [00:16, 65.25it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 741it [00:16, 64.91it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 748it [00:16, 63.99it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 755it [00:16, 65.49it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 762it [00:16, 66.71it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 769it [00:16, 67.26it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 777it [00:16, 68.64it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 784it [00:16, 67.98it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 791it [00:16, 67.53it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 798it [00:17, 67.49it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 805it [00:17, 65.79it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 812it [00:17, 65.57it/s]\u001b[A\n",
      "[PROCESS]:  18%|‚ñà‚ñä        | 8/45 [00:22<01:45,  2.86s/it]\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 826it [00:17, 62.67it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 833it [00:17, 62.27it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 840it [00:17, 63.88it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 848it [00:17, 66.95it/s]\u001b[A\n",
      "[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [02:57<00:00,  3.94s/it]\n",
      "[2025-12-01 20:41:25] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to ./tmp_out/seed_iv.\n",
      "[2025-12-01 20:41:25] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m./tmp_out/seed_iv\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Data\n",
    "dataset = SEEDIVDataset(\n",
    "    io_path='./tmp_out/seed_iv',\n",
    "    root_path='/kaggle/input/seed-iv/eeg_raw_data',\n",
    "    offline_transform=t_transform,\n",
    "    label_transform=transforms.Compose([\n",
    "        transforms.Select('emotion'),\n",
    "    ]),\n",
    "    chunk_size=800,  # 4 seconds\n",
    "    num_worker=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f43ac5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.326735Z",
     "iopub.status.busy": "2025-12-01T20:41:25.326507Z",
     "iopub.status.idle": "2025-12-01T20:41:25.341537Z",
     "shell.execute_reply": "2025-12-01T20:41:25.340939Z"
    },
    "papermill": {
     "duration": 0.042429,
     "end_time": "2025-12-01T20:41:25.342540",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.300111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Segments: 37575\n",
      "------------------------------\n",
      "Count per Emotion:\n",
      "emotion\n",
      "0    10170\n",
      "1    10245\n",
      "2     9225\n",
      "3     7935\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "Percentage per Emotion:\n",
      "emotion\n",
      "0    27.07\n",
      "1    27.27\n",
      "2    24.55\n",
      "3    21.12\n",
      "Name: count, dtype: float64\n",
      "\n",
      "‚úÖ Data is reasonably BALANCED (Diff: 6.15%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Get the metadata DataFrame\n",
    "df = dataset.info\n",
    "\n",
    "# 2. Count the segments for each emotion\n",
    "# 0: Neutral, 1: Sad, 2: Fear, 3: Happy\n",
    "counts = df['emotion'].value_counts().sort_index()\n",
    "total = len(df)\n",
    "\n",
    "print(f\"Total Segments: {total}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Count per Emotion:\")\n",
    "print(counts)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Percentage per Emotion:\")\n",
    "percentages = (counts / total) * 100\n",
    "print(percentages.round(2))\n",
    "\n",
    "# 3. Check for Imbalance\n",
    "# If the difference between max and min is > 10%, we might need a WeightedSampler\n",
    "max_pct = percentages.max()\n",
    "min_pct = percentages.min()\n",
    "\n",
    "if (max_pct - min_pct) > 10:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Data is IMBALANCED (Diff: {max_pct - min_pct:.2f}%)\")\n",
    "    print(\"Consider using a WeightedRandomSampler.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Data is reasonably BALANCED (Diff: {max_pct - min_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9dade38",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.395121Z",
     "iopub.status.busy": "2025-12-01T20:41:25.394903Z",
     "iopub.status.idle": "2025-12-01T20:41:25.405494Z",
     "shell.execute_reply": "2025-12-01T20:41:25.404978Z"
    },
    "papermill": {
     "duration": 0.038372,
     "end_time": "2025-12-01T20:41:25.406454",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.368082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split by Trial ID\n",
    "# SEED-IV has 24 trials (videos) per session.\n",
    "# 80% of VIDEOS for training (19 videos), 20% for testing (5 videos).\n",
    "all_trial_ids = list(range(1, 25))\n",
    "\n",
    "random.seed(42)\n",
    "test_trial_ids = random.sample(all_trial_ids, 5)\n",
    "train_trial_ids = [t for t in all_trial_ids if t not in test_trial_ids]\n",
    "\n",
    "train_indices = df[df['trial_id'].isin(train_trial_ids)].index.tolist()\n",
    "test_indices = df[df['trial_id'].isin(test_trial_ids)].index.tolist()\n",
    "\n",
    "# Create Subsets & Loaders\n",
    "train_set = Subset(dataset, train_indices)\n",
    "test_set = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254ef2b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.458926Z",
     "iopub.status.busy": "2025-12-01T20:41:25.458722Z",
     "iopub.status.idle": "2025-12-01T20:41:25.476546Z",
     "shell.execute_reply": "2025-12-01T20:41:25.476032Z"
    },
    "papermill": {
     "duration": 0.045293,
     "end_time": "2025-12-01T20:41:25.477576",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.432283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import namedtuple\n",
    "from typing import Any, Callable, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torchvision.models.googlenet import BasicConv2d, Inception, InceptionAux\n",
    "# Assuming BasicConv2d, Inception, InceptionAux are defined elsewhere, \n",
    "# as in torchvision, or included in your actual setup.\n",
    "# For this code to run, you would need to define or import them.\n",
    "\n",
    "# --- Definitions (Assuming the originals are used, but with reduced params) ---\n",
    "# We keep the original namedtuple structure for type hints\n",
    "GoogLeNetOutputs = namedtuple(\n",
    "    \"GoogLeNetOutputs\", [\"logits\", \"aux_logits2\", \"aux_logits1\"]\n",
    ")\n",
    "GoogLeNetOutputs.__annotations__ = {\n",
    "    \"logits\": Tensor,\n",
    "    \"aux_logits2\": Optional[Tensor],\n",
    "    \"aux_logits1\": Optional[Tensor],\n",
    "}\n",
    "_GoogLeNetOutputs = GoogLeNetOutputs\n",
    "\n",
    "\n",
    "# Placeholder for original blocks if you don't have them imported:\n",
    "# class BasicConv2d(nn.Module): ...\n",
    "# class Inception(nn.Module): ...\n",
    "# class InceptionAux(nn.Module): ...\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class GoogLeNetLighter(nn.Module):\n",
    "    __constants__ = [\"aux_logits\", \"transform_input\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 4,\n",
    "        aux_logits: bool = False, # Set to False for lighter model\n",
    "        transform_input: bool = False,\n",
    "        init_weights: Optional[bool] = None,\n",
    "        blocks: Optional[list[Callable[..., nn.Module]]] = None,\n",
    "        dropout: float = 0.4, # Increased dropout slightly\n",
    "        dropout_aux: float = 0.7,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if blocks is None:\n",
    "            # Note: We must use the original blocks (BasicConv2d, Inception, InceptionAux)\n",
    "            # but with reduced channel counts in the calls below.\n",
    "            # Replace with your actual blocks if they are locally defined.\n",
    "            conv_block = BasicConv2d\n",
    "            inception_block = Inception\n",
    "            inception_aux_block = InceptionAux\n",
    "        else:\n",
    "            if len(blocks) != 3:\n",
    "                raise ValueError(f\"blocks length should be 3 instead of {len(blocks)}\")\n",
    "            conv_block = blocks[0]\n",
    "            inception_block = blocks[1]\n",
    "            inception_aux_block = blocks[2]\n",
    "\n",
    "        if init_weights is None:\n",
    "            init_weights = True\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "        # 1. INPUT CHANNEL: 1 instead of 3 (62x800 input)\n",
    "        # 2. REDUCED FILTERS & STRIDE: \n",
    "        #    - Filters: 64 -> 32\n",
    "        #    - Kernel: 7x7 -> 5x5\n",
    "        #    - Stride: 2 -> 1 (to preserve height)\n",
    "        self.conv1 = conv_block(1, 32, kernel_size=5, stride=1, padding=2) # Output: N x 32 x 62 x 800\n",
    "        \n",
    "        # MaxPool with a larger stride on the width (800)\n",
    "        self.maxpool1 = nn.MaxPool2d((3, 5), stride=(1, 2), ceil_mode=True) # Output: N x 32 x 62 x 400\n",
    "\n",
    "        # REDUCED FILTERS: 64 -> 32\n",
    "        self.conv2 = conv_block(32, 32, kernel_size=1) # Output: N x 32 x 62 x 400\n",
    "        # REDUCED FILTERS: 192 -> 96\n",
    "        self.conv3 = conv_block(32, 96, kernel_size=3, padding=1) # Output: N x 96 x 62 x 400\n",
    "        \n",
    "        # MaxPool with stride 2 on both dimensions to start downsampling\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True) # Output: N x 96 x 31 x 200\n",
    "\n",
    "        # --- Inception Modules (Channels Halved/Reduced) ---\n",
    "        # Original: (192, 64, 96, 128, 16, 32, 32) -> Output: 256\n",
    "        # Reduced: (96, 32, 48, 64, 8, 16, 16) -> Output: 128\n",
    "        self.inception3a = inception_block(96, 32, 48, 64, 8, 16, 16) # Output: N x 128 x 31 x 200\n",
    "        # Original: (256, 128, 128, 192, 32, 96, 64) -> Output: 480\n",
    "        # Reduced: (128, 64, 64, 96, 16, 48, 32) -> Output: 240\n",
    "        self.inception3b = inception_block(128, 64, 64, 96, 16, 48, 32) # Output: N x 240 x 31 x 200\n",
    "        \n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True) # Output: N x 240 x 16 x 100\n",
    "\n",
    "        # Original: (480, 192, 96, 208, 16, 48, 64) -> Output: 512\n",
    "        # Reduced: (240, 96, 48, 104, 8, 24, 32) -> Output: 256\n",
    "        self.inception4a = inception_block(240, 96, 48, 104, 8, 24, 32) # Output: N x 256 x 16 x 100\n",
    "        \n",
    "        # AUXILIARY HEADS REMOVED\n",
    "        if aux_logits:\n",
    "            warnings.warn(\"Auxiliary heads are not recommended for the lighter model.\")\n",
    "            # Still defining them if aux_logits is forced to True\n",
    "            self.aux1 = inception_aux_block(512, num_classes, dropout=dropout_aux)\n",
    "            self.aux2 = inception_aux_block(528, num_classes, dropout=dropout_aux)\n",
    "        else:\n",
    "            self.aux1 = None  # type: ignore[assignment]\n",
    "            self.aux2 = None  # type: ignore[assignment]\n",
    "\n",
    "        # Original: (512, 160, 112, 224, 24, 64, 64) -> Output: 512\n",
    "        # Reduced: (256, 80, 56, 112, 12, 32, 32) -> Output: 256\n",
    "        self.inception4b = inception_block(256, 80, 56, 112, 12, 32, 32) # Output: N x 256 x 16 x 100\n",
    "        # Original: (512, 128, 128, 256, 24, 64, 64) -> Output: 512\n",
    "        # Reduced: (256, 64, 64, 128, 12, 32, 32) -> Output: 256\n",
    "        self.inception4c = inception_block(256, 64, 64, 128, 12, 32, 32) # Output: N x 256 x 16 x 100\n",
    "        # Original: (512, 112, 144, 288, 32, 64, 64) -> Output: 528\n",
    "        # Reduced: (256, 56, 72, 144, 16, 32, 32) -> Output: 264\n",
    "        # self.inception4d = inception_block(256, 56, 72, 144, 16, 32, 32) # Output: N x 264 x 16 x 100\n",
    "        # Original: (528, 256, 160, 320, 32, 128, 128) -> Output: 832\n",
    "        # Reduced: (264, 128, 80, 160, 16, 64, 64) -> Output: 416\n",
    "        # self.inception4e = inception_block(264, 128, 80, 160, 16, 64, 64) # Output: N x 416 x 16 x 100\n",
    "        \n",
    "        self.maxpool4 = nn.MaxPool2d((2, 4), stride=(2, 2), ceil_mode=True) # Output: N x 416 x 8 x 50\n",
    "\n",
    "        # Original: (832, 256, 160, 320, 32, 128, 128) -> Output: 832\n",
    "        # Reduced: (416, 128, 80, 160, 16, 64, 64) -> Output: 416\n",
    "        self.inception5a = inception_block(256, 128, 80, 160, 16, 64, 64) # Output: N x 416 x 8 x 50\n",
    "        # Original: (832, 384, 192, 384, 48, 128, 128) -> Output: 1024\n",
    "        # Reduced: (416, 192, 96, 192, 24, 64, 64) -> Output: 512\n",
    "        self.inception5b = inception_block(416, 192, 96, 192, 24, 64, 64) # Output: N x 512 x 8 x 50\n",
    "\n",
    "        # Changed to reduce the output size of the inception block, \n",
    "        # so final feature map depth is 512, not 1024.\n",
    "        \n",
    "        # Global Average Pooling still pools down to (1, 1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # Output: N x 512 x 1 x 1\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Reduced input to Linear layer: 1024 -> 512\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    # _transform_input is only relevant for 3-channel image data, keeping it for completeness \n",
    "    # but it won't be used with 1-channel data.\n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            warnings.warn(\"Input transformation is for 3-channel data and may not be correct for 1-channel signal.\")\n",
    "            # Original code assumes 3 channels, needs adaptation for 1 channel if normalization is desired\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x: Tensor) -> tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        # N x 1 x 62 x 800\n",
    "        x = self.conv1(x) # N x 32 x 62 x 800\n",
    "        x = self.maxpool1(x) # N x 32 x 62 x 400\n",
    "        x = self.conv2(x) # N x 32 x 62 x 400\n",
    "        x = self.conv3(x) # N x 96 x 62 x 400\n",
    "        x = self.maxpool2(x) # N x 96 x 31 x 200\n",
    "\n",
    "        x = self.inception3a(x) # N x 128 x 31 x 200\n",
    "        x = self.inception3b(x) # N x 240 x 31 x 200\n",
    "        x = self.maxpool3(x) # N x 240 x 16 x 100\n",
    "\n",
    "        x = self.inception4a(x) # N x 256 x 16 x 100\n",
    "        \n",
    "        # AUXILIARY HEADS REMOVED\n",
    "        aux1: Optional[Tensor] = None\n",
    "        aux2: Optional[Tensor] = None\n",
    "        # if self.aux1 is not None: ...\n",
    "        x = self.inception4b(x) # N x 256 x 16 x 100\n",
    "        x = self.inception4c(x) # N x 256 x 16 x 100\n",
    "        # x = self.inception4d(x) # N x 264 x 16 x 100\n",
    "        \n",
    "        # if self.aux2 is not None: ...\n",
    "\n",
    "        # x = self.inception4e(x) # N x 416 x 16 x 100\n",
    "        x = self.maxpool4(x) # N x 416 x 8 x 50\n",
    "        x = self.inception5a(x) # N x 416 x 8 x 50\n",
    "        x = self.inception5b(x) # N x 512 x 8 x 50\n",
    "\n",
    "        x = self.avgpool(x) # N x 512 x 1 x 1\n",
    "        x = torch.flatten(x, 1) # N x 512\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x) # N x num_classes\n",
    "        \n",
    "        return x, aux2, aux1\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(\n",
    "        self, x: Tensor, aux2: Optional[Tensor], aux1: Optional[Tensor]\n",
    "    ) -> GoogLeNetOutputs:\n",
    "        if self.training and self.aux_logits:\n",
    "            return _GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return x  # type: ignore[return-value]\n",
    "\n",
    "    def forward(self, x: Tensor) -> GoogLeNetOutputs:\n",
    "        x = self._transform_input(x)\n",
    "        x, aux2, aux1 = self._forward(x)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\n",
    "                    \"Scripted GoogleNet always returns GoogleNetOutputs Tuple\"\n",
    "                )\n",
    "            return GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            # We explicitly pass None for aux2, aux1 since aux_logits=False\n",
    "            return self.eager_outputs(x, None, None) \n",
    "\n",
    "\n",
    "# The googlenet factory function would also need to be updated \n",
    "# to use GoogLeNetLighter and potentially remove the weights loading \n",
    "# since a custom architecture is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1dc50cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.529950Z",
     "iopub.status.busy": "2025-12-01T20:41:25.529752Z",
     "iopub.status.idle": "2025-12-01T20:41:25.761316Z",
     "shell.execute_reply": "2025-12-01T20:41:25.760710Z"
    },
    "papermill": {
     "duration": 0.259156,
     "end_time": "2025-12-01T20:41:25.762719",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.503563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GoogLeNetLighter(init_weights=True, dropout=0.9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a6764b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.816667Z",
     "iopub.status.busy": "2025-12-01T20:41:25.816025Z",
     "iopub.status.idle": "2025-12-01T20:41:25.819339Z",
     "shell.execute_reply": "2025-12-01T20:41:25.818771Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.030897,
     "end_time": "2025-12-01T20:41:25.820355",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.789458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Define Model\n",
    "# model = EEGNet(\n",
    "#     chunk_size=800,\n",
    "#     num_electrodes=62,\n",
    "#     dropout=0.5,\n",
    "#     kernel_1=64,\n",
    "#     kernel_2=16,\n",
    "#     F1=8,\n",
    "#     F2=16,\n",
    "#     D=2,\n",
    "#     num_classes=4  \n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f33e0e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.872955Z",
     "iopub.status.busy": "2025-12-01T20:41:25.872495Z",
     "iopub.status.idle": "2025-12-01T20:41:25.876804Z",
     "shell.execute_reply": "2025-12-01T20:41:25.876181Z"
    },
    "papermill": {
     "duration": 0.031791,
     "end_time": "2025-12-01T20:41:25.877815",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.846024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Training Loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "055da0c9",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-01T20:41:25.930553Z",
     "iopub.status.busy": "2025-12-01T20:41:25.930361Z",
     "iopub.status.idle": "2025-12-01T22:08:23.253726Z",
     "shell.execute_reply": "2025-12-01T22:08:23.252947Z"
    },
    "papermill": {
     "duration": 5217.378052,
     "end_time": "2025-12-01T22:08:23.281820",
     "exception": false,
     "start_time": "2025-12-01T20:41:25.903768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3384 (Acc=34.01%) | Val Loss=2.6543 (Acc=13.80%)\n",
      "  --> New Best! 13.80%\n",
      "Epoch 2: Train Loss=1.2233 (Acc=44.08%) | Val Loss=1.5793 (Acc=28.32%)\n",
      "  --> New Best! 28.32%\n",
      "Epoch 3: Train Loss=1.1209 (Acc=51.30%) | Val Loss=1.3616 (Acc=42.59%)\n",
      "  --> New Best! 42.59%\n",
      "Epoch 4: Train Loss=1.0295 (Acc=56.72%) | Val Loss=1.4436 (Acc=41.26%)\n",
      "Epoch 5: Train Loss=0.9479 (Acc=61.35%) | Val Loss=1.3369 (Acc=42.99%)\n",
      "  --> New Best! 42.99%\n",
      "Epoch 6: Train Loss=0.8702 (Acc=65.37%) | Val Loss=1.3518 (Acc=46.34%)\n",
      "  --> New Best! 46.34%\n",
      "Epoch 7: Train Loss=0.7969 (Acc=68.66%) | Val Loss=1.3539 (Acc=47.49%)\n",
      "  --> New Best! 47.49%\n",
      "Epoch 8: Train Loss=0.7307 (Acc=71.91%) | Val Loss=1.5149 (Acc=41.94%)\n",
      "Epoch 9: Train Loss=0.6768 (Acc=73.88%) | Val Loss=1.2840 (Acc=51.48%)\n",
      "  --> New Best! 51.48%\n",
      "Epoch 10: Train Loss=0.6213 (Acc=76.39%) | Val Loss=1.3318 (Acc=53.52%)\n",
      "  --> New Best! 53.52%\n",
      "Epoch 11: Train Loss=0.5722 (Acc=78.45%) | Val Loss=1.4487 (Acc=50.13%)\n",
      "Epoch 12: Train Loss=0.5393 (Acc=79.57%) | Val Loss=1.8568 (Acc=44.15%)\n",
      "Epoch 13: Train Loss=0.4921 (Acc=81.48%) | Val Loss=1.7941 (Acc=44.15%)\n",
      "Epoch 14: Train Loss=0.4565 (Acc=83.05%) | Val Loss=1.8884 (Acc=43.05%)\n",
      "Epoch 15: Train Loss=0.4278 (Acc=84.34%) | Val Loss=1.6400 (Acc=47.77%)\n",
      "Epoch 16: Train Loss=0.3951 (Acc=85.50%) | Val Loss=1.7207 (Acc=50.60%)\n",
      "Epoch 17: Train Loss=0.3744 (Acc=86.63%) | Val Loss=1.6175 (Acc=45.66%)\n",
      "Epoch 18: Train Loss=0.3407 (Acc=87.83%) | Val Loss=2.5073 (Acc=40.69%)\n",
      "Epoch 19: Train Loss=0.3277 (Acc=88.20%) | Val Loss=1.8722 (Acc=51.00%)\n",
      "Epoch 20: Train Loss=0.3032 (Acc=89.00%) | Val Loss=2.0993 (Acc=43.41%)\n",
      "Epoch 21: Train Loss=0.2661 (Acc=90.58%) | Val Loss=1.8898 (Acc=49.58%)\n",
      "Epoch 22: Train Loss=0.2687 (Acc=90.42%) | Val Loss=1.9982 (Acc=46.69%)\n",
      "Epoch 23: Train Loss=0.2480 (Acc=91.01%) | Val Loss=2.5142 (Acc=41.81%)\n",
      "Epoch 24: Train Loss=0.2363 (Acc=91.67%) | Val Loss=2.3946 (Acc=42.66%)\n",
      "Epoch 25: Train Loss=0.2180 (Acc=92.43%) | Val Loss=2.3224 (Acc=50.38%)\n",
      "  --> Early Stopping.\n",
      "Finished. Best Acc: 53.52%\n"
     ]
    }
   ],
   "source": [
    "patience = 15\n",
    "counter = 0\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        X = batch[0].to(device).float()\n",
    "        y = batch[1].to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += y.size(0)\n",
    "        correct_train += (predicted == y).sum().item()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_acc = (correct_train / total_train) * 100\n",
    "\n",
    "    # ==========================\n",
    "    # 2. VALIDATION PHASE\n",
    "    # ==========================\n",
    "    model.eval() # Turn off dropout for accurate testing\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad(): # Don't calculate gradients for validation (saves memory)\n",
    "        for batch in test_loader:\n",
    "            X = batch[0].to(device).float()\n",
    "            y = batch[1].to(device).long()\n",
    "            \n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += y.size(0)\n",
    "            correct_val += (predicted == y).sum().item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_acc = (correct_val / total_val) * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} (Acc={train_acc:.2f}%) | Val Loss={avg_val_loss:.4f} (Acc={val_acc:.2f}%)\")\n",
    "     # --- EARLY STOPPING ---\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), 'best_googlenet15_final.pth')\n",
    "        print(f\"  --> New Best! {best_val_acc:.2f}%\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"  --> Early Stopping.\")\n",
    "            break\n",
    "\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Finished. Best Acc: {best_val_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 218098,
     "sourceId": 472319,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6273.541468,
   "end_time": "2025-12-01T22:08:26.630355",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T20:23:53.088887",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
