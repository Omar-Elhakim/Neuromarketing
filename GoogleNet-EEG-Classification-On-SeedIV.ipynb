{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95bcd951",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:42:36.686848Z",
     "iopub.status.busy": "2025-12-02T20:42:36.685992Z",
     "iopub.status.idle": "2025-12-02T20:42:36.700297Z",
     "shell.execute_reply": "2025-12-02T20:42:36.699700Z"
    },
    "papermill": {
     "duration": 0.020657,
     "end_time": "2025-12-02T20:42:36.701546",
     "exception": false,
     "start_time": "2025-12-02T20:42:36.680889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a198175",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:42:36.708747Z",
     "iopub.status.busy": "2025-12-02T20:42:36.708140Z",
     "iopub.status.idle": "2025-12-02T20:56:42.911097Z",
     "shell.execute_reply": "2025-12-02T20:56:42.910223Z"
    },
    "papermill": {
     "duration": 846.208016,
     "end_time": "2025-12-02T20:56:42.912610",
     "exception": false,
     "start_time": "2025-12-02T20:42:36.704594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torcheeg\r\n",
      "  Downloading torcheeg-1.1.3.tar.gz (251 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting torch-scatter\r\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (4.67.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.2.3)\r\n",
      "Requirement already satisfied: xlrd>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.0.2)\r\n",
      "Collecting scipy<=1.10.1,>=1.7.3 (from torcheeg)\r\n",
      "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.2.2)\r\n",
      "Collecting lmdb>=1.3.0 (from torcheeg)\r\n",
      "  Downloading lmdb-1.7.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: einops>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (0.8.1)\r\n",
      "Requirement already satisfied: mne>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.10.2)\r\n",
      "Collecting xmltodict>=0.13.0 (from torcheeg)\r\n",
      "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (3.5)\r\n",
      "Requirement already satisfied: PyWavelets>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.8.0)\r\n",
      "Collecting spectrum>=0.8.1 (from torcheeg)\r\n",
      "  Downloading spectrum-0.9.0.tar.gz (231 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torchmetrics>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (1.8.2)\r\n",
      "Collecting mne_connectivity>=0.4.0 (from torcheeg)\r\n",
      "  Downloading mne_connectivity-0.7.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: pytorch-lightning>=1.9.5 in /usr/local/lib/python3.11/dist-packages (from torcheeg) (2.5.5)\r\n",
      "Collecting wfdb>=4.1.2 (from torcheeg)\r\n",
      "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.15.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (4.4.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (0.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (3.7.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (25.0)\r\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne>=1.0.3->torcheeg) (1.8.2)\r\n",
      "INFO: pip is looking at multiple versions of mne to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting mne>=1.0.3 (from torcheeg)\r\n",
      "  Downloading mne-1.11.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting matplotlib>=3.8 (from mne>=1.0.3->torcheeg)\r\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting mne>=1.0.3 (from torcheeg)\r\n",
      "  Downloading mne-1.10.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "  Downloading mne-1.10.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting netCDF4>=1.6.5 (from mne_connectivity>=0.4.0->torcheeg)\r\n",
      "  Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: xarray>=2023.11.0 in /usr/local/lib/python3.11/dist-packages (from mne_connectivity>=0.4.0->torcheeg) (2025.7.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.5->torcheeg) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->torcheeg) (2025.2)\r\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (6.0.3)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.9.5->torcheeg) (0.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->torcheeg) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->torcheeg) (3.6.0)\r\n",
      "Collecting easydev (from spectrum>=0.8.1->torcheeg)\r\n",
      "  Downloading easydev-0.13.3-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (3.13.2)\r\n",
      "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (2.32.5)\r\n",
      "INFO: pip is looking at multiple versions of wfdb to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting wfdb>=4.1.2 (from torcheeg)\r\n",
      "  Downloading wfdb-4.2.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb>=4.1.2->torcheeg) (0.13.1)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.9.5->torcheeg) (75.2.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->mne>=1.0.3->torcheeg) (3.0.9)\r\n",
      "Collecting cftime (from netCDF4>=1.6.5->mne_connectivity>=0.4.0->torcheeg)\r\n",
      "  Downloading cftime-1.6.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.6.5->mne_connectivity>=0.4.0->torcheeg) (2025.10.5)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (4.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->torcheeg) (1.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb>=4.1.2->torcheeg) (2.5.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from SoundFile>=0.10.0->wfdb>=4.1.2->torcheeg) (2.0.0)\r\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (0.4.6)\r\n",
      "Requirement already satisfied: colorlog<7.0.0,>=6.8.2 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (6.10.1)\r\n",
      "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev->spectrum>=0.8.1->torcheeg)\r\n",
      "  Downloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\r\n",
      "Requirement already satisfied: pexpect<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.9.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.5->torcheeg) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.5->torcheeg) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.5->torcheeg) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.5->torcheeg) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.5->torcheeg) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb>=4.1.2->torcheeg) (1.22.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb>=4.1.2->torcheeg) (2.23)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.5->torcheeg) (2024.2.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect<5.0.0,>=4.9.0->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lmdb-1.7.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (295 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.1/295.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mne-1.9.0-py3-none-any.whl (7.4 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mne_connectivity-0.7.0-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wfdb-4.1.2-py3-none-any.whl (159 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\r\n",
      "Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.5 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading easydev-0.13.3-py3-none-any.whl (57 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading line_profiler-4.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (750 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cftime-1.6.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: torcheeg, torch-scatter, spectrum\r\n",
      "  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for torcheeg: filename=torcheeg-1.1.3-py3-none-any.whl size=466286 sha256=395c2c9033ab8d9281b4f7c5b4df8f5116f63751255c0959e81ca5e24b9116f9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/7e/e1/7004a323c223a4fce1b1c4b2c2afd8f608b4b5591a39008416\r\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3936069 sha256=a7b3dd95faecb62477e993a19d042780e606a25d7f7b72a9d25eec81babfa88c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\r\n",
      "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for spectrum: filename=spectrum-0.9.0-cp311-cp311-linux_x86_64.whl size=236751 sha256=3bdedf755b9c5f4f3c5e7123ca1c5640942a570a0d09b18c5b714f4e0021e00e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/9c/de/eb558fbd03ea1540d3c908f23681f57f9d9e8c2a5cd08d6f42\r\n",
      "Successfully built torcheeg torch-scatter spectrum\r\n",
      "Installing collected packages: lmdb, xmltodict, torch-scatter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, line-profiler, nvidia-cusparse-cu12, nvidia-cudnn-cu12, easydev, nvidia-cusolver-cu12, scipy, cftime, netCDF4, mne, wfdb, spectrum, mne_connectivity, torcheeg\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: line-profiler\r\n",
      "    Found existing installation: line_profiler 5.0.0\r\n",
      "    Uninstalling line_profiler-5.0.0:\r\n",
      "      Successfully uninstalled line_profiler-5.0.0\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.3\r\n",
      "    Uninstalling scipy-1.15.3:\r\n",
      "      Successfully uninstalled scipy-1.15.3\r\n",
      "  Attempting uninstall: mne\r\n",
      "    Found existing installation: mne 1.10.2\r\n",
      "    Uninstalling mne-1.10.2:\r\n",
      "      Successfully uninstalled mne-1.10.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle-environments 1.18.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed cftime-1.6.5 easydev-0.13.3 line-profiler-4.2.0 lmdb-1.7.5 mne-1.9.0 mne_connectivity-0.7.0 netCDF4-1.7.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 scipy-1.10.1 spectrum-0.9.0 torch-scatter-2.1.2 torcheeg-1.1.3 wfdb-4.1.2 xmltodict-1.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheeg torch-scatter torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97404f61",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:56:42.961660Z",
     "iopub.status.busy": "2025-12-02T20:56:42.960942Z",
     "iopub.status.idle": "2025-12-02T20:56:55.053332Z",
     "shell.execute_reply": "2025-12-02T20:56:55.052715Z"
    },
    "papermill": {
     "duration": 12.11932,
     "end_time": "2025-12-02T20:56:55.054764",
     "exception": false,
     "start_time": "2025-12-02T20:56:42.935444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torcheeg.datasets import SEEDIVDataset\n",
    "from torcheeg import transforms\n",
    "import scipy.signal as signal\n",
    "import random\n",
    "import copy\n",
    "from torch import Tensor\n",
    "from torchvision.models.googlenet import BasicConv2d\n",
    "from typing import Callable, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87478b63",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:56:55.099770Z",
     "iopub.status.busy": "2025-12-02T20:56:55.099323Z",
     "iopub.status.idle": "2025-12-02T20:56:55.131889Z",
     "shell.execute_reply": "2025-12-02T20:56:55.131199Z"
    },
    "papermill": {
     "duration": 0.056268,
     "end_time": "2025-12-02T20:56:55.133058",
     "exception": false,
     "start_time": "2025-12-02T20:56:55.076790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Setup Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe7c34a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:56:55.177156Z",
     "iopub.status.busy": "2025-12-02T20:56:55.176939Z",
     "iopub.status.idle": "2025-12-02T20:56:55.180747Z",
     "shell.execute_reply": "2025-12-02T20:56:55.180200Z"
    },
    "papermill": {
     "duration": 0.027047,
     "end_time": "2025-12-02T20:56:55.181841",
     "exception": false,
     "start_time": "2025-12-02T20:56:55.154794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BandPassFilter(eeg_data):\n",
    "    b, a = signal.butter(4, Wn=[1.0, 75.0], btype='bandpass', fs=200)\n",
    "    return signal.filtfilt(b, a, eeg_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e14a0fa",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:56:55.227419Z",
     "iopub.status.busy": "2025-12-02T20:56:55.227147Z",
     "iopub.status.idle": "2025-12-02T20:56:55.231005Z",
     "shell.execute_reply": "2025-12-02T20:56:55.230364Z"
    },
    "papermill": {
     "duration": 0.027285,
     "end_time": "2025-12-02T20:56:55.232015",
     "exception": false,
     "start_time": "2025-12-02T20:56:55.204730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Notch(eeg_data):\n",
    "    b, a = signal.iirnotch(w0=50.0, Q=30.0, fs=200)\n",
    "    return signal.filtfilt(b, a, eeg_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e7c8f3",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:56:55.275515Z",
     "iopub.status.busy": "2025-12-02T20:56:55.275315Z",
     "iopub.status.idle": "2025-12-02T20:56:55.278679Z",
     "shell.execute_reply": "2025-12-02T20:56:55.278097Z"
    },
    "papermill": {
     "duration": 0.026266,
     "end_time": "2025-12-02T20:56:55.279709",
     "exception": false,
     "start_time": "2025-12-02T20:56:55.253443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Define Preprocessing\n",
    "t_transform = transforms.Compose([\n",
    "    transforms.Lambda(BandPassFilter),\n",
    "    transforms.Lambda(Notch),\n",
    "    transforms.BaselineRemoval(),\n",
    "    transforms.MeanStdNormalize(),\n",
    "    transforms.To2d()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c766028",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T20:56:55.323698Z",
     "iopub.status.busy": "2025-12-02T20:56:55.323490Z",
     "iopub.status.idle": "2025-12-02T21:00:17.646941Z",
     "shell.execute_reply": "2025-12-02T21:00:17.646074Z"
    },
    "papermill": {
     "duration": 202.347001,
     "end_time": "2025-12-02T21:00:17.648366",
     "exception": false,
     "start_time": "2025-12-02T20:56:55.301365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-02 20:56:55] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m./tmp_out/seed_iv\u001b[0m.\n",
      "[2025-12-02 20:56:55] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
      "[PROCESS]:   0%|          | 0/45 [00:00<?, ?it/s]\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 0it [00:00, ?it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 1it [00:03,  3.55s/it]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 7it [00:03,  2.59it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 14it [00:03,  6.09it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 21it [00:03, 10.44it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 28it [00:03, 15.62it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 35it [00:04, 21.53it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 42it [00:04, 27.83it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 49it [00:04, 33.96it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 56it [00:04, 39.61it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 63it [00:04, 44.71it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 70it [00:04, 49.15it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 77it [00:04, 53.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 84it [00:04, 55.74it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 92it [00:04, 60.51it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 99it [00:05, 61.75it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 106it [00:05, 62.23it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 113it [00:05, 63.41it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 120it [00:05, 62.93it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 127it [00:05, 63.15it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 134it [00:05, 62.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 141it [00:05, 62.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 148it [00:05, 63.23it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 155it [00:05, 59.75it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 162it [00:06, 53.71it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 168it [00:06, 53.82it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 175it [00:06, 56.92it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 181it [00:06, 57.41it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 188it [00:06, 59.55it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 195it [00:06, 60.91it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 202it [00:06, 62.72it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 209it [00:06, 62.61it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 216it [00:07, 62.77it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 223it [00:07, 62.76it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 230it [00:07, 64.06it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 237it [00:07, 64.18it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 244it [00:07, 64.40it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 251it [00:07, 63.76it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 258it [00:07, 64.74it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 265it [00:07, 65.95it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 272it [00:07, 65.75it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 279it [00:07, 66.12it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 286it [00:08, 27.04it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 291it [00:08, 30.30it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 298it [00:08, 36.67it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 305it [00:08, 42.14it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 312it [00:09, 47.55it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 319it [00:09, 51.26it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 326it [00:09, 55.24it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 333it [00:09, 57.62it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 340it [00:09, 59.98it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 347it [00:09, 60.76it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 354it [00:09, 62.86it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 361it [00:09, 63.21it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 368it [00:09, 62.20it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 375it [00:09, 63.09it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 382it [00:10, 61.94it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 389it [00:10, 62.63it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 397it [00:10, 65.19it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 404it [00:10, 65.31it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 411it [00:10, 66.22it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 418it [00:10, 64.98it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 425it [00:10, 65.95it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 432it [00:10, 65.29it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 439it [00:10, 65.03it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 446it [00:11, 64.87it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 453it [00:11, 64.33it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 460it [00:11, 63.05it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 467it [00:11, 63.38it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 474it [00:11, 64.26it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 481it [00:11, 64.89it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 488it [00:11, 61.48it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 495it [00:11, 60.77it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 502it [00:11, 61.32it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 509it [00:12, 63.66it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 516it [00:12, 63.52it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 523it [00:12, 63.02it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 530it [00:12, 64.23it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 537it [00:12, 65.32it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 544it [00:12, 65.86it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 551it [00:12, 66.54it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 559it [00:12, 67.81it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 566it [00:12, 68.26it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 573it [00:13, 67.65it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 581it [00:13, 68.47it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 588it [00:13, 66.18it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 595it [00:13, 65.50it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 602it [00:13, 64.61it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 609it [00:13, 65.06it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 616it [00:13, 64.64it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 623it [00:13, 55.70it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 630it [00:13, 57.47it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 637it [00:14, 60.08it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 644it [00:14, 60.87it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 651it [00:14, 62.66it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 658it [00:14, 63.36it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 666it [00:14, 64.94it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 673it [00:14, 65.15it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 680it [00:14, 65.74it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 687it [00:14, 64.53it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 694it [00:14, 64.28it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 701it [00:15, 65.52it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 708it [00:15, 65.40it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 715it [00:15, 61.82it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 722it [00:15, 62.74it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 729it [00:15, 61.62it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 736it [00:15, 62.39it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 743it [00:15, 60.59it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 750it [00:15, 61.70it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 757it [00:16, 58.05it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 764it [00:16, 59.89it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 771it [00:16, 61.44it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 778it [00:16, 62.42it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 785it [00:16, 63.17it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 792it [00:16, 63.08it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 799it [00:16, 63.10it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 806it [00:16, 63.59it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 813it [00:16, 62.20it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 820it [00:16, 63.11it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 827it [00:17, 64.17it/s]\u001b[A\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 834it [00:17, 65.10it/s]\u001b[A\n",
      "[PROCESS]:  18%|‚ñà‚ñä        | 8/45 [00:23<01:46,  2.88s/it]\n",
      "[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 848it [00:17, 65.17it/s]\u001b[A\n",
      "[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [02:54<00:00,  3.87s/it]\n",
      "[2025-12-02 21:00:17] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to ./tmp_out/seed_iv.\n",
      "[2025-12-02 21:00:17] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m./tmp_out/seed_iv\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Data\n",
    "dataset = SEEDIVDataset(\n",
    "    io_path='./tmp_out/seed_iv',\n",
    "    root_path='/kaggle/input/seed-iv/eeg_raw_data',\n",
    "    offline_transform=t_transform,\n",
    "    label_transform=transforms.Compose([\n",
    "        transforms.Select('emotion'),\n",
    "    ]),\n",
    "    chunk_size=800,  # 4 seconds\n",
    "    num_worker=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc15dbf",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:17.702054Z",
     "iopub.status.busy": "2025-12-02T21:00:17.701468Z",
     "iopub.status.idle": "2025-12-02T21:00:17.718715Z",
     "shell.execute_reply": "2025-12-02T21:00:17.718075Z"
    },
    "papermill": {
     "duration": 0.045062,
     "end_time": "2025-12-02T21:00:17.719781",
     "exception": false,
     "start_time": "2025-12-02T21:00:17.674719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Segments: 37575\n",
      "------------------------------\n",
      "Count per Emotion:\n",
      "emotion\n",
      "0    10170\n",
      "1    10245\n",
      "2     9225\n",
      "3     7935\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "Percentage per Emotion:\n",
      "emotion\n",
      "0    27.07\n",
      "1    27.27\n",
      "2    24.55\n",
      "3    21.12\n",
      "Name: count, dtype: float64\n",
      "\n",
      "‚úÖ Data is reasonably BALANCED (Diff: 6.15%)\n"
     ]
    }
   ],
   "source": [
    "# 1. Get the metadata DataFrame\n",
    "df = dataset.info\n",
    "\n",
    "# 2. Count the segments for each emotion\n",
    "# 0: Neutral, 1: Sad, 2: Fear, 3: Happy\n",
    "counts = df['emotion'].value_counts().sort_index()\n",
    "total = len(df)\n",
    "\n",
    "print(f\"Total Segments: {total}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Count per Emotion:\")\n",
    "print(counts)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Percentage per Emotion:\")\n",
    "percentages = (counts / total) * 100\n",
    "print(percentages.round(2))\n",
    "\n",
    "# 3. Check for Imbalance\n",
    "# If the difference between max and min is > 10%, we might need a WeightedSampler\n",
    "max_pct = percentages.max()\n",
    "min_pct = percentages.min()\n",
    "\n",
    "if (max_pct - min_pct) > 10:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Data is IMBALANCED (Diff: {max_pct - min_pct:.2f}%)\")\n",
    "    print(\"Consider using a WeightedRandomSampler.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Data is reasonably BALANCED (Diff: {max_pct - min_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4102d16",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:17.772448Z",
     "iopub.status.busy": "2025-12-02T21:00:17.772235Z",
     "iopub.status.idle": "2025-12-02T21:00:17.782943Z",
     "shell.execute_reply": "2025-12-02T21:00:17.782164Z"
    },
    "papermill": {
     "duration": 0.037702,
     "end_time": "2025-12-02T21:00:17.784005",
     "exception": false,
     "start_time": "2025-12-02T21:00:17.746303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split by Trial ID\n",
    "# SEED-IV has 24 trials (videos) per session.\n",
    "# 80% of VIDEOS for training (19 videos), 20% for testing (5 videos).\n",
    "all_trial_ids = list(range(1, 25))\n",
    "\n",
    "random.seed(42)\n",
    "test_trial_ids = random.sample(all_trial_ids, 5)\n",
    "train_trial_ids = [t for t in all_trial_ids if t not in test_trial_ids]\n",
    "\n",
    "train_indices = df[df['trial_id'].isin(train_trial_ids)].index.tolist()\n",
    "test_indices = df[df['trial_id'].isin(test_trial_ids)].index.tolist()\n",
    "\n",
    "# Create Subsets & Loaders\n",
    "train_set = Subset(dataset, train_indices)\n",
    "test_set = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03adc6c8",
   "metadata": {
    "papermill": {
     "duration": 0.025677,
     "end_time": "2025-12-02T21:00:17.835508",
     "exception": false,
     "start_time": "2025-12-02T21:00:17.809831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Inception Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e90d6c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:17.889815Z",
     "iopub.status.busy": "2025-12-02T21:00:17.889038Z",
     "iopub.status.idle": "2025-12-02T21:00:17.896803Z",
     "shell.execute_reply": "2025-12-02T21:00:17.896035Z"
    },
    "papermill": {
     "duration": 0.037131,
     "end_time": "2025-12-02T21:00:17.898063",
     "exception": false,
     "start_time": "2025-12-02T21:00:17.860932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        ch1x1: int,\n",
    "        ch3x3red: int,\n",
    "        ch3x3: int,\n",
    "        ch5x5red: int,\n",
    "        ch5x5: int,\n",
    "        pool_proj: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, ch3x3red, kernel_size=1),\n",
    "            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
    "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
    "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
    "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
    "            conv_block(in_channels, pool_proj, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def _forward(self, x: Tensor) -> list[Tensor]:\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c05fa3",
   "metadata": {
    "papermill": {
     "duration": 0.025394,
     "end_time": "2025-12-02T21:00:17.949321",
     "exception": false,
     "start_time": "2025-12-02T21:00:17.923927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### GoogleNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11202e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:18.002324Z",
     "iopub.status.busy": "2025-12-02T21:00:18.002065Z",
     "iopub.status.idle": "2025-12-02T21:00:18.014239Z",
     "shell.execute_reply": "2025-12-02T21:00:18.013529Z"
    },
    "papermill": {
     "duration": 0.04078,
     "end_time": "2025-12-02T21:00:18.015328",
     "exception": false,
     "start_time": "2025-12-02T21:00:17.974548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cprint(x):\n",
    "    printEnabled = False\n",
    "    if printEnabled:\n",
    "        print(x)\n",
    "\n",
    "\n",
    "class GoogLeNetLighter(nn.Module):\n",
    "    __constants__ = [\"transform_input\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 4,\n",
    "        transform_input: bool = False,\n",
    "        init_weights: Optional[bool] = None,\n",
    "        blocks: Optional[list[Callable[..., nn.Module]]] = None,\n",
    "        dropout: float = 0.4,  # Increased dropout slightly\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if blocks is None:\n",
    "            conv_block = BasicConv2d\n",
    "            inception_block = Inception\n",
    "        else:\n",
    "            if len(blocks) != 2:\n",
    "                raise ValueError(f\"blocks length should be 2 instead of {len(blocks)}\")\n",
    "            conv_block = blocks[0]\n",
    "            inception_block = blocks[1]\n",
    "\n",
    "        if init_weights is None:\n",
    "            init_weights = True\n",
    "\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "        self.conv1 = conv_block(1, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d((3, 5), stride=(1, 2), ceil_mode=True)\n",
    "\n",
    "        self.conv2 = conv_block(32, 32, kernel_size=1)\n",
    "        self.conv3 = conv_block(32, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception3a = inception_block(96, 32, 48, 64, 8, 16, 16)\n",
    "        self.inception3b = inception_block(128, 64, 64, 96, 16, 48, 32)\n",
    "\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.fc = nn.Linear(240, num_classes)\n",
    "\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        cprint(\"*\" * 30)\n",
    "        x = self.conv1(x)\n",
    "        cprint(f\"conv1       = {x.shape}\")\n",
    "        x = self.maxpool1(x)\n",
    "        cprint(f\"maxpool1    = {x.shape}\")\n",
    "        x = self.conv2(x)\n",
    "        cprint(f\"conv2       = {x.shape}\")\n",
    "        x = self.conv3(x)\n",
    "        cprint(f\"conv3       = {x.shape}\")\n",
    "        x = self.maxpool2(x)\n",
    "        cprint(f\"maxpool2    = {x.shape}\")\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "        cprint(f\"inception3a = {x.shape}\")\n",
    "        x = self.inception3b(x)\n",
    "        cprint(f\"inception3b = {x.shape}\")\n",
    "        x = self.maxpool3(x)\n",
    "        cprint(f\"maxpool3    = {x.shape}\")\n",
    "\n",
    "        x = self.avgpool(x)  \n",
    "        cprint(f\"avgpool = {x.shape}\")\n",
    "        x = torch.flatten(x, 1)\n",
    "        cprint(f\"flatten = {x.shape}\")\n",
    "        x = self.dropout(x)\n",
    "        cprint(f\"dropout = {x.shape}\")\n",
    "        x = self.fc(x)\n",
    "        cprint(f\"fc = {x.shape}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self._forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5535dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:18.067320Z",
     "iopub.status.busy": "2025-12-02T21:00:18.067068Z",
     "iopub.status.idle": "2025-12-02T21:00:18.293038Z",
     "shell.execute_reply": "2025-12-02T21:00:18.292215Z"
    },
    "papermill": {
     "duration": 0.253525,
     "end_time": "2025-12-02T21:00:18.294487",
     "exception": false,
     "start_time": "2025-12-02T21:00:18.040962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GoogLeNetLighter(init_weights=True, dropout=0.9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd63210",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:18.347827Z",
     "iopub.status.busy": "2025-12-02T21:00:18.347346Z",
     "iopub.status.idle": "2025-12-02T21:00:18.351571Z",
     "shell.execute_reply": "2025-12-02T21:00:18.350832Z"
    },
    "papermill": {
     "duration": 0.032147,
     "end_time": "2025-12-02T21:00:18.352677",
     "exception": false,
     "start_time": "2025-12-02T21:00:18.320530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Training Loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e753098d",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-02T21:00:18.404708Z",
     "iopub.status.busy": "2025-12-02T21:00:18.404480Z",
     "iopub.status.idle": "2025-12-02T23:09:14.595872Z",
     "shell.execute_reply": "2025-12-02T23:09:14.594921Z"
    },
    "papermill": {
     "duration": 7736.246813,
     "end_time": "2025-12-02T23:09:14.624766",
     "exception": false,
     "start_time": "2025-12-02T21:00:18.377953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3797 (Acc=28.46%) | Val Loss=1.3448 (Acc=33.52%)\n",
      "  --> New Best! 33.52%\n",
      "Epoch 2: Train Loss=1.3439 (Acc=33.07%) | Val Loss=1.4319 (Acc=31.21%)\n",
      "Epoch 3: Train Loss=1.3162 (Acc=35.55%) | Val Loss=1.3575 (Acc=36.68%)\n",
      "  --> New Best! 36.68%\n",
      "Epoch 4: Train Loss=1.2956 (Acc=37.28%) | Val Loss=1.3402 (Acc=32.93%)\n",
      "Epoch 5: Train Loss=1.2826 (Acc=38.65%) | Val Loss=1.4053 (Acc=23.38%)\n",
      "Epoch 6: Train Loss=1.2712 (Acc=39.02%) | Val Loss=1.6418 (Acc=17.90%)\n",
      "Epoch 7: Train Loss=1.2582 (Acc=40.09%) | Val Loss=2.1696 (Acc=16.23%)\n",
      "Epoch 8: Train Loss=1.2447 (Acc=41.61%) | Val Loss=1.3334 (Acc=36.45%)\n",
      "Epoch 9: Train Loss=1.2336 (Acc=42.49%) | Val Loss=1.4445 (Acc=23.95%)\n",
      "Epoch 10: Train Loss=1.2207 (Acc=43.34%) | Val Loss=1.3298 (Acc=32.94%)\n",
      "Epoch 11: Train Loss=1.2138 (Acc=43.88%) | Val Loss=1.3135 (Acc=38.35%)\n",
      "  --> New Best! 38.35%\n",
      "Epoch 12: Train Loss=1.2016 (Acc=44.93%) | Val Loss=1.8255 (Acc=31.23%)\n",
      "Epoch 13: Train Loss=1.1919 (Acc=45.17%) | Val Loss=1.5646 (Acc=24.77%)\n",
      "Epoch 14: Train Loss=1.1805 (Acc=46.11%) | Val Loss=1.4361 (Acc=26.52%)\n",
      "Epoch 15: Train Loss=1.1747 (Acc=46.45%) | Val Loss=1.2486 (Acc=43.19%)\n",
      "  --> New Best! 43.19%\n",
      "Epoch 16: Train Loss=1.1655 (Acc=46.91%) | Val Loss=1.3717 (Acc=29.58%)\n",
      "Epoch 17: Train Loss=1.1602 (Acc=47.73%) | Val Loss=1.3117 (Acc=35.93%)\n",
      "Epoch 18: Train Loss=1.1501 (Acc=48.14%) | Val Loss=1.3080 (Acc=39.45%)\n",
      "Epoch 19: Train Loss=1.1422 (Acc=48.82%) | Val Loss=1.3106 (Acc=37.94%)\n",
      "Epoch 20: Train Loss=1.1396 (Acc=49.16%) | Val Loss=1.5540 (Acc=26.21%)\n",
      "Epoch 21: Train Loss=1.1357 (Acc=49.75%) | Val Loss=1.7003 (Acc=22.73%)\n",
      "Epoch 22: Train Loss=1.1208 (Acc=50.15%) | Val Loss=1.4106 (Acc=34.61%)\n",
      "Epoch 23: Train Loss=1.1184 (Acc=50.38%) | Val Loss=1.3255 (Acc=39.94%)\n",
      "Epoch 24: Train Loss=1.1123 (Acc=50.63%) | Val Loss=1.3119 (Acc=38.38%)\n",
      "Epoch 25: Train Loss=1.1082 (Acc=51.06%) | Val Loss=1.5125 (Acc=33.69%)\n",
      "Epoch 26: Train Loss=1.1024 (Acc=51.76%) | Val Loss=1.3677 (Acc=41.75%)\n",
      "Epoch 27: Train Loss=1.0976 (Acc=51.50%) | Val Loss=1.3215 (Acc=37.62%)\n",
      "Epoch 28: Train Loss=1.0815 (Acc=52.95%) | Val Loss=1.3412 (Acc=34.18%)\n",
      "Epoch 29: Train Loss=1.0809 (Acc=52.94%) | Val Loss=1.3403 (Acc=37.11%)\n",
      "Epoch 30: Train Loss=1.0734 (Acc=52.99%) | Val Loss=1.2447 (Acc=45.54%)\n",
      "  --> New Best! 45.54%\n",
      "Epoch 31: Train Loss=1.0687 (Acc=53.79%) | Val Loss=1.3823 (Acc=42.50%)\n",
      "Epoch 32: Train Loss=1.0600 (Acc=53.91%) | Val Loss=1.5962 (Acc=32.05%)\n",
      "Epoch 33: Train Loss=1.0534 (Acc=54.36%) | Val Loss=1.4155 (Acc=39.78%)\n",
      "Epoch 34: Train Loss=1.0512 (Acc=54.43%) | Val Loss=1.3871 (Acc=39.40%)\n",
      "Epoch 35: Train Loss=1.0434 (Acc=55.27%) | Val Loss=1.2097 (Acc=45.00%)\n",
      "Epoch 36: Train Loss=1.0375 (Acc=55.26%) | Val Loss=1.4666 (Acc=36.69%)\n",
      "Epoch 37: Train Loss=1.0291 (Acc=55.89%) | Val Loss=1.4095 (Acc=39.36%)\n",
      "Epoch 38: Train Loss=1.0309 (Acc=55.85%) | Val Loss=1.3756 (Acc=46.36%)\n",
      "  --> New Best! 46.36%\n",
      "Epoch 39: Train Loss=1.0249 (Acc=56.30%) | Val Loss=1.6752 (Acc=27.79%)\n",
      "Epoch 40: Train Loss=1.0121 (Acc=56.97%) | Val Loss=1.3780 (Acc=37.88%)\n",
      "Epoch 41: Train Loss=1.0113 (Acc=57.04%) | Val Loss=1.2787 (Acc=44.99%)\n",
      "Epoch 42: Train Loss=1.0047 (Acc=57.08%) | Val Loss=1.4579 (Acc=33.06%)\n",
      "Epoch 43: Train Loss=0.9987 (Acc=57.87%) | Val Loss=1.3105 (Acc=41.97%)\n",
      "Epoch 44: Train Loss=0.9970 (Acc=57.64%) | Val Loss=1.3085 (Acc=45.38%)\n",
      "Epoch 45: Train Loss=0.9881 (Acc=58.08%) | Val Loss=1.4650 (Acc=31.56%)\n",
      "Epoch 46: Train Loss=0.9820 (Acc=58.49%) | Val Loss=1.5076 (Acc=42.56%)\n",
      "Epoch 47: Train Loss=0.9708 (Acc=58.80%) | Val Loss=1.3886 (Acc=39.28%)\n",
      "Epoch 48: Train Loss=0.9738 (Acc=59.14%) | Val Loss=1.3746 (Acc=45.61%)\n",
      "Epoch 49: Train Loss=0.9654 (Acc=59.34%) | Val Loss=1.3625 (Acc=39.82%)\n",
      "Epoch 50: Train Loss=0.9667 (Acc=59.41%) | Val Loss=1.3118 (Acc=38.93%)\n",
      "Epoch 51: Train Loss=0.9525 (Acc=60.00%) | Val Loss=1.4126 (Acc=37.56%)\n",
      "Epoch 52: Train Loss=0.9486 (Acc=60.34%) | Val Loss=1.3528 (Acc=46.02%)\n",
      "Epoch 53: Train Loss=0.9465 (Acc=60.42%) | Val Loss=1.6469 (Acc=33.86%)\n",
      "  --> Early Stopping.\n",
      "Finished. Best Acc: 46.36%\n"
     ]
    }
   ],
   "source": [
    "patience = 15\n",
    "counter = 0\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        X = batch[0].to(device).float()\n",
    "        y = batch[1].to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += y.size(0)\n",
    "        correct_train += (predicted == y).sum().item()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_acc = (correct_train / total_train) * 100\n",
    "\n",
    "    # ==========================\n",
    "    # 2. VALIDATION PHASE\n",
    "    # ==========================\n",
    "    model.eval() # Turn off dropout for accurate testing\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad(): # Don't calculate gradients for validation (saves memory)\n",
    "        for batch in test_loader:\n",
    "            X = batch[0].to(device).float()\n",
    "            y = batch[1].to(device).long()\n",
    "            \n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += y.size(0)\n",
    "            correct_val += (predicted == y).sum().item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_acc = (correct_val / total_val) * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} (Acc={train_acc:.2f}%) | Val Loss={avg_val_loss:.4f} (Acc={val_acc:.2f}%)\")\n",
    "     # --- EARLY STOPPING ---\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), 'best_googlenet15_final.pth')\n",
    "        print(f\"  --> New Best! {best_val_acc:.2f}%\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"  --> Early Stopping.\")\n",
    "            break\n",
    "\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Finished. Best Acc: {best_val_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 218098,
     "sourceId": 472319,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8805.020465,
   "end_time": "2025-12-02T23:09:17.873369",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-02T20:42:32.852904",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
