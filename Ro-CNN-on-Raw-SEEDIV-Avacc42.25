{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":472319,"sourceType":"datasetVersion","datasetId":218098}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:32:49.999420Z","iopub.execute_input":"2025-11-30T21:32:49.999679Z","iopub.status.idle":"2025-11-30T21:32:50.003354Z","shell.execute_reply.started":"2025-11-30T21:32:49.999658Z","shell.execute_reply":"2025-11-30T21:32:50.002602Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install torch_scatter torcheeg torch_geometric -qq ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:32:50.004326Z","iopub.execute_input":"2025-11-30T21:32:50.004520Z","iopub.status.idle":"2025-11-30T21:46:32.960473Z","shell.execute_reply.started":"2025-11-30T21:32:50.004497Z","shell.execute_reply":"2025-11-30T21:46:32.959759Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.1/295.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\njax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nscikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nxarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#!rm -rf tmp_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:32.961861Z","iopub.execute_input":"2025-11-30T21:46:32.962094Z","iopub.status.idle":"2025-11-30T21:46:32.966499Z","shell.execute_reply.started":"2025-11-30T21:46:32.962069Z","shell.execute_reply":"2025-11-30T21:46:32.965787Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset, Dataset, WeightedRandomSampler\nfrom torcheeg.datasets import SEEDIVDataset\nfrom torcheeg import transforms\nimport scipy.signal as signal\nimport numpy as np\nimport random\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nimport copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:32.967218Z","iopub.execute_input":"2025-11-30T21:46:32.967504Z","iopub.status.idle":"2025-11-30T21:46:37.516323Z","shell.execute_reply.started":"2025-11-30T21:46:32.967478Z","shell.execute_reply":"2025-11-30T21:46:37.515740Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Set device to GPU if available, otherwise CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:37.517784Z","iopub.execute_input":"2025-11-30T21:46:37.518187Z","iopub.status.idle":"2025-11-30T21:46:37.549532Z","shell.execute_reply.started":"2025-11-30T21:46:37.518168Z","shell.execute_reply":"2025-11-30T21:46:37.548717Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Set a fixed random seed for reproducibility across different libraries.\ndef set_seed(seed_value=42):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed_value)\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:37.550441Z","iopub.execute_input":"2025-11-30T21:46:37.550771Z","iopub.status.idle":"2025-11-30T21:46:37.573336Z","shell.execute_reply.started":"2025-11-30T21:46:37.550740Z","shell.execute_reply":"2025-11-30T21:46:37.572747Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def BandPassFilter(eeg_data):\n    b, a = signal.butter(4, Wn=[1.0, 75.0], btype='bandpass', fs=200)\n    return signal.filtfilt(b, a, eeg_data, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:37.574051Z","iopub.execute_input":"2025-11-30T21:46:37.574223Z","iopub.status.idle":"2025-11-30T21:46:37.583817Z","shell.execute_reply.started":"2025-11-30T21:46:37.574209Z","shell.execute_reply":"2025-11-30T21:46:37.583278Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def Notch(eeg_data):\n    b, a = signal.iirnotch(w0=50.0, Q=30.0, fs=200)\n    return signal.filtfilt(b, a, eeg_data, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:37.584649Z","iopub.execute_input":"2025-11-30T21:46:37.584898Z","iopub.status.idle":"2025-11-30T21:46:37.598123Z","shell.execute_reply.started":"2025-11-30T21:46:37.584882Z","shell.execute_reply":"2025-11-30T21:46:37.597578Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 2. Define Preprocessing\nt_transform = transforms.Compose([\n    transforms.Lambda(BandPassFilter),\n    transforms.Lambda(Notch),\n    transforms.BaselineRemoval(),\n    transforms.MeanStdNormalize(),\n    transforms.To2d()\n    \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:37.598960Z","iopub.execute_input":"2025-11-30T21:46:37.599208Z","iopub.status.idle":"2025-11-30T21:46:37.612415Z","shell.execute_reply.started":"2025-11-30T21:46:37.599187Z","shell.execute_reply":"2025-11-30T21:46:37.611714Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = SEEDIVDataset(\n    io_path='./tmp_out/seed_iv',\n    root_path='/kaggle/input/seed-iv/eeg_raw_data',\n    offline_transform=t_transform,\n    label_transform=transforms.Select('emotion'),\n    chunk_size=800,  # 4 seconds\n    num_worker=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:46:37.613071Z","iopub.execute_input":"2025-11-30T21:46:37.613313Z","iopub.status.idle":"2025-11-30T21:55:35.592558Z","shell.execute_reply.started":"2025-11-30T21:46:37.613289Z","shell.execute_reply":"2025-11-30T21:55:35.592001Z"}},"outputs":[{"name":"stderr","text":"[2025-11-30 21:46:37] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m./tmp_out/seed_iv\u001b[0m.\n[2025-11-30 21:46:37] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n[PROCESS]:   0%|          | 0/45 [00:00<?, ?it/s]\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 0it [00:00, ?it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 1it [00:04,  4.66s/it]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 11it [00:04,  3.18it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 21it [00:04,  7.12it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 31it [00:04, 12.22it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 42it [00:05, 19.21it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 53it [00:05, 27.66it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 64it [00:05, 37.21it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 75it [00:05, 47.28it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 86it [00:05, 57.51it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 97it [00:05, 66.99it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 108it [00:05, 75.14it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 119it [00:05, 81.87it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 130it [00:05, 87.08it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 141it [00:06, 91.59it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 152it [00:06, 94.41it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 163it [00:06, 96.30it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 174it [00:06, 97.37it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 185it [00:06, 97.44it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 196it [00:06, 98.43it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 207it [00:06, 97.79it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 217it [00:06, 98.34it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 228it [00:06, 100.97it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 239it [00:06, 101.56it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 250it [00:07, 97.43it/s] \u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 261it [00:07, 99.86it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 272it [00:07, 100.21it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 283it [00:07, 101.04it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 294it [00:07, 102.42it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 305it [00:07, 100.50it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 316it [00:07, 100.42it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 327it [00:07, 100.22it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 338it [00:07, 99.86it/s] \u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 348it [00:08, 98.37it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 358it [00:08, 98.25it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 368it [00:08, 96.31it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 378it [00:08, 95.92it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 388it [00:08, 96.73it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 399it [00:08, 98.98it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 410it [00:08, 99.37it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 420it [00:08, 98.96it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 430it [00:08, 99.25it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 441it [00:09, 99.61it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 451it [00:09, 99.28it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 462it [00:09, 99.85it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 473it [00:09, 100.45it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 484it [00:09, 101.16it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 495it [00:09, 101.83it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 506it [00:09, 101.53it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 517it [00:09, 101.38it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 528it [00:09, 101.30it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 539it [00:10, 99.86it/s] \u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 549it [00:10, 35.65it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 559it [00:10, 43.49it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 569it [00:10, 51.91it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 579it [00:11, 60.20it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 589it [00:11, 68.06it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 599it [00:11, 75.07it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 609it [00:11, 80.73it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 620it [00:11, 87.39it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 631it [00:11, 91.30it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 642it [00:11, 94.20it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 653it [00:11, 97.05it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 664it [00:11, 98.99it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 675it [00:11, 100.89it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 686it [00:12, 102.67it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 697it [00:12, 102.95it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 708it [00:12, 103.75it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 719it [00:12, 102.74it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 730it [00:12, 102.71it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 741it [00:12, 102.36it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 752it [00:12, 96.43it/s] \u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 762it [00:12, 92.92it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 772it [00:13, 88.79it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 782it [00:13, 90.07it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 793it [00:13, 93.31it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 804it [00:13, 95.45it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 815it [00:13, 96.96it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 826it [00:13, 97.85it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 837it [00:13, 99.80it/s]\u001b[A\n[RECORD /kaggle/input/seed-iv/eeg_raw_data/1/4_20151111.mat]: 849it [00:13, 102.99it/s]\u001b[A\n[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [08:57<00:00, 11.95s/it]                             \u001b[A\n[2025-11-30 21:55:35] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to ./tmp_out/seed_iv.\n[2025-11-30 21:55:35] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m./tmp_out/seed_iv\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"df = dataset.info\ncounts = df['emotion'].value_counts().sort_index()\nprint(\"Class Counts:\\n\", counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:55:35.594504Z","iopub.execute_input":"2025-11-30T21:55:35.595078Z","iopub.status.idle":"2025-11-30T21:55:35.605801Z","shell.execute_reply.started":"2025-11-30T21:55:35.595057Z","shell.execute_reply":"2025-11-30T21:55:35.605230Z"}},"outputs":[{"name":"stdout","text":"Class Counts:\n emotion\n0    10170\n1    10245\n2     9225\n3     7935\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"BATCH_SIZE = 16               \nMAX_EPOCHS = 60\nPATIENCE = 10                 \nSCHED_FACTOR = 0.3\nSCHED_PATIENCE = 3\nLEARNING_RATE = 3e-4\nWEIGHT_DECAY = 1e-4\nCLIP_GRAD = 1.0  \nN_SPLITS = 5 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:55:35.606427Z","iopub.execute_input":"2025-11-30T21:55:35.606619Z","iopub.status.idle":"2025-11-30T21:55:35.619263Z","shell.execute_reply.started":"2025-11-30T21:55:35.606604Z","shell.execute_reply":"2025-11-30T21:55:35.618628Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class EEG_CNN(nn.Module):\n\n    def __init__(self, in_channels=1, num_classes=4):\n        super().__init__()\n\n        self.print_dims = True\n\n        # ----- Block 1 -----\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, 32, kernel_size=(1,9), padding=(0,4)),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d((1,2)),\n            nn.Dropout(0.1)\n        )\n\n        # ----- Block 2 -----\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=(1,7), padding=(0,3)),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d((1,2)),\n            nn.Dropout(0.15)\n        )\n\n        # ----- Block 3 -----\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=(1,5), padding=(0,1)),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d((1,2)),\n            nn.Dropout(0.2)\n        )\n\n        # ----- Block 4 -----\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=(1,3), padding=(0,1)),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d((1,2)),\n            nn.Dropout(0.25)\n        )\n\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=(1,3), padding=(0,1)),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d((1,2)),\n            nn.Dropout(0.3)\n        )\n\n        #self.flatten = nn.Flatten()\n        # Global pooling instead of flatten (saves memory)\n        self.gap = nn.AdaptiveAvgPool2d((1,1))  \n\n        # ----- FC Layers -----\n        self.fc = nn.Sequential(\n            nn.Flatten(),  \n            nn.LazyLinear(256),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n\n            nn.Linear(256, num_classes)\n        )\n\n\n    def forward(self, x):\n\n        if self.print_dims: print(\"Input : H =\", x.shape[2], \"W =\", x.shape[3])\n\n        x = self.conv1(x)\n        if self.print_dims: print(\"After Conv1 :H =\", x.shape[2], \"W =\", x.shape[3])\n\n        x = self.conv2(x)\n        if self.print_dims: print(\"After Conv2 :H =\", x.shape[2], \"W =\", x.shape[3])\n\n        x = self.conv3(x)\n        if self.print_dims: print(\"After Conv3 :H =\", x.shape[2], \"W =\", x.shape[3])\n\n        x = self.conv4(x)\n        if self.print_dims: print(\"After Conv4 :H =\", x.shape[2], \"W =\", x.shape[3])\n\n        x = self.conv5(x)\n        if self.print_dims: print(\"After Conv5 :H =\", x.shape[2], \"W =\", x.shape[3])\n\n        x = self.gap(x) \n        if self.print_dims:\n            print(\"After Flatten :\", x.shape)\n            self.print_dims = False\n\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T22:01:42.947168Z","iopub.execute_input":"2025-11-30T22:01:42.947949Z","iopub.status.idle":"2025-11-30T22:01:42.964512Z","shell.execute_reply.started":"2025-11-30T22:01:42.947923Z","shell.execute_reply":"2025-11-30T22:01:42.963726Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n#scaler = torch.amp.GradScaler(device=\"cuda\", enabled=True)\nscaler = torch.amp.GradScaler(device.type if device.type == 'cuda' else 'cpu')\n\n\ndef train_epoch(model, loader, criterion, optimizer, clip_grad=None):\n    model.train()\n    loss_sum = 0.0\n    correct = 0\n    total = 0\n\n    for X, y in loader:\n        X = X.to(device).float()\n        y = y.to(device).long()\n\n        optimizer.zero_grad()\n        #with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n        with torch.amp.autocast(device.type if device.type == 'cuda' else 'cpu'):\n            out = model(X)\n            loss = criterion(out, y)\n\n        scaler.scale(loss).backward()\n\n        if clip_grad:\n            # unscale then clip\n            scaler.unscale_(optimizer)\n            nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n\n        scaler.step(optimizer)\n        scaler.update()\n\n        batch = y.size(0)\n        loss_sum += loss.item() * batch\n        correct += (out.argmax(1) == y).sum().item()\n        total += batch\n\n    return loss_sum / total, 100.0 * correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:56:29.894974Z","iopub.execute_input":"2025-11-30T21:56:29.895659Z","iopub.status.idle":"2025-11-30T21:56:29.902041Z","shell.execute_reply.started":"2025-11-30T21:56:29.895633Z","shell.execute_reply":"2025-11-30T21:56:29.901011Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def evaluate(model, loader, criterion):\n    model.eval()\n    loss_sum = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for X, y in loader:\n            X = X.to(device).float()\n            y = y.to(device).long()\n            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n                out = model(X)\n                loss = criterion(out, y)\n\n            batch = y.size(0)\n            loss_sum += loss.item() * batch\n            correct += (out.argmax(1) == y).sum().item()\n            total += batch\n\n    return loss_sum / total, 100.0 * correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:56:33.944876Z","iopub.execute_input":"2025-11-30T21:56:33.945728Z","iopub.status.idle":"2025-11-30T21:56:33.950951Z","shell.execute_reply.started":"2025-11-30T21:56:33.945679Z","shell.execute_reply":"2025-11-30T21:56:33.950286Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, scheduler,\n                              max_epochs=MAX_EPOCHS, patience=PATIENCE, clip_grad=CLIP_GRAD):\n    best_acc = 0.0\n    best_state = None\n    counter = 0\n\n    for epoch in range(max_epochs):\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, clip_grad=clip_grad)\n        val_loss, val_acc = evaluate(model, val_loader, criterion)\n\n        scheduler.step(val_loss)\n\n        print(f\"Epoch {epoch+1:02d} | Train={train_acc:.2f}% | Val={val_acc:.2f}% | ValLoss={val_loss:.4f}\")\n\n        if val_acc > best_acc + 1e-4:   # small delta to avoid noise\n            best_acc = val_acc\n            best_state = copy.deepcopy(model.state_dict())\n            counter = 0\n        else:\n            counter += 1\n            if counter >= patience:\n                print(f\"Early stopping (no improvement for {patience} epochs).\")\n                break\n\n    return best_acc, best_state\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:56:39.117034Z","iopub.execute_input":"2025-11-30T21:56:39.117717Z","iopub.status.idle":"2025-11-30T21:56:39.122995Z","shell.execute_reply.started":"2025-11-30T21:56:39.117672Z","shell.execute_reply":"2025-11-30T21:56:39.122123Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\nkf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\nfold_results = []\n\nprint(\"\\n========== Starting Cross‚ÄëValidation ==========\\n\")\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n    print(f\"\\n----- Fold {fold+1} -----\")\n\n    # free GPU memory from previous fold\n    if device.type == 'cuda':\n        torch.cuda.empty_cache()\n\n    # compute per-fold class weights\n    train_labels = df.iloc[train_idx]['emotion'].values\n    class_counts = np.bincount(train_labels)\n    class_weights = 1.0 / class_counts\n    sample_weights = class_weights[train_labels]\n\n    sampler = WeightedRandomSampler(\n        weights=torch.DoubleTensor(sample_weights),\n        num_samples=len(sample_weights),\n        replacement=True\n    )\n\n    # DataLoaders\n    train_loader = DataLoader(\n        Subset(dataset, train_idx),\n        batch_size=BATCH_SIZE,\n        sampler=sampler,\n        num_workers=0,\n        pin_memory=(device.type == 'cuda')\n    )\n\n    val_loader = DataLoader(\n        Subset(dataset, val_idx),\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=0,\n        pin_memory=(device.type == 'cuda')\n    )\n\n    # Model, optimizer, scheduler\n    model = EEG_CNN().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=SCHED_FACTOR, patience=SCHED_PATIENCE, verbose=True)\n\n    # Train\n    best_acc, best_state = train_with_early_stopping(\n        model, train_loader, val_loader, criterion, optimizer, scheduler,\n        max_epochs=MAX_EPOCHS, patience=PATIENCE, clip_grad=CLIP_GRAD\n    )\n\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    fold_results.append(best_acc)\n    print(f\"Best Accuracy (Fold {fold+1}): {best_acc:.2f}%\")\n\n# Final summary\nprint(\"\\n========== Final Cross‚ÄëValidation Results ==========\")\nfor i, acc in enumerate(fold_results):\n    print(f\"Fold {i+1}: {acc:.2f}%\")\nprint(\"\\nAverage Accuracy =\", np.mean(fold_results))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T22:01:49.949787Z","iopub.execute_input":"2025-11-30T22:01:49.950344Z","iopub.status.idle":"2025-12-01T07:43:00.376017Z","shell.execute_reply.started":"2025-11-30T22:01:49.950323Z","shell.execute_reply":"2025-12-01T07:43:00.375357Z"}},"outputs":[{"name":"stdout","text":"\n========== Starting Cross‚ÄëValidation ==========\n\n\n----- Fold 1 -----\nInput : H = 62 W = 800\nAfter Conv1 :H = 62 W = 400\nAfter Conv2 :H = 62 W = 200\nAfter Conv3 :H = 62 W = 99\nAfter Conv4 :H = 62 W = 49\nAfter Conv5 :H = 62 W = 24\nAfter Flatten : torch.Size([16, 512, 1, 1])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1341851955.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train=28.71% | Val=30.05% | ValLoss=1.3740\nEpoch 02 | Train=29.71% | Val=26.59% | ValLoss=1.3882\nEpoch 03 | Train=30.76% | Val=30.42% | ValLoss=1.3655\nEpoch 04 | Train=31.76% | Val=31.98% | ValLoss=1.3511\nEpoch 05 | Train=33.20% | Val=27.01% | ValLoss=1.3946\nEpoch 06 | Train=33.20% | Val=30.88% | ValLoss=1.3517\nEpoch 07 | Train=34.29% | Val=32.06% | ValLoss=1.3501\nEpoch 08 | Train=34.91% | Val=34.44% | ValLoss=1.3344\nEpoch 09 | Train=35.39% | Val=33.80% | ValLoss=1.3320\nEpoch 10 | Train=35.60% | Val=34.04% | ValLoss=1.3395\nEpoch 11 | Train=37.21% | Val=35.53% | ValLoss=1.3369\nEpoch 12 | Train=37.74% | Val=38.24% | ValLoss=1.3201\nEpoch 13 | Train=38.91% | Val=35.86% | ValLoss=1.3316\nEpoch 14 | Train=39.27% | Val=35.83% | ValLoss=1.3424\nEpoch 15 | Train=39.74% | Val=39.21% | ValLoss=1.3093\nEpoch 16 | Train=39.83% | Val=40.36% | ValLoss=1.2783\nEpoch 17 | Train=40.57% | Val=39.91% | ValLoss=1.2936\nEpoch 18 | Train=41.15% | Val=36.62% | ValLoss=1.3196\nEpoch 19 | Train=41.34% | Val=37.10% | ValLoss=1.3429\nEpoch 20 | Train=41.34% | Val=29.83% | ValLoss=1.5481\nEpoch 21 | Train=43.99% | Val=42.29% | ValLoss=1.2690\nEpoch 22 | Train=43.99% | Val=42.54% | ValLoss=1.2646\nEpoch 23 | Train=44.64% | Val=40.65% | ValLoss=1.2892\nEpoch 24 | Train=44.54% | Val=41.24% | ValLoss=1.2815\nEpoch 25 | Train=44.98% | Val=40.73% | ValLoss=1.2843\nEpoch 26 | Train=45.51% | Val=42.82% | ValLoss=1.2613\nEpoch 27 | Train=46.27% | Val=41.25% | ValLoss=1.2847\nEpoch 28 | Train=45.77% | Val=42.38% | ValLoss=1.2625\nEpoch 29 | Train=46.37% | Val=40.32% | ValLoss=1.3059\nEpoch 30 | Train=46.21% | Val=41.77% | ValLoss=1.2814\nEpoch 31 | Train=46.86% | Val=42.49% | ValLoss=1.2758\nEpoch 32 | Train=47.98% | Val=40.28% | ValLoss=1.3156\nEpoch 33 | Train=47.24% | Val=41.76% | ValLoss=1.2765\nEpoch 34 | Train=47.99% | Val=42.75% | ValLoss=1.2630\nEpoch 35 | Train=47.82% | Val=41.56% | ValLoss=1.2917\nEpoch 36 | Train=48.71% | Val=42.00% | ValLoss=1.2883\nEarly stopping (no improvement for 10 epochs).\nBest Accuracy (Fold 1): 42.82%\n\n----- Fold 2 -----\nInput : H = 62 W = 800\nAfter Conv1 :H = 62 W = 400\nAfter Conv2 :H = 62 W = 200\nAfter Conv3 :H = 62 W = 99\nAfter Conv4 :H = 62 W = 49\nAfter Conv5 :H = 62 W = 24\nAfter Flatten : torch.Size([16, 512, 1, 1])\nEpoch 01 | Train=28.42% | Val=30.30% | ValLoss=1.3784\nEpoch 02 | Train=30.18% | Val=30.73% | ValLoss=1.3611\nEpoch 03 | Train=30.68% | Val=29.54% | ValLoss=1.3605\nEpoch 04 | Train=31.87% | Val=28.85% | ValLoss=1.3678\nEpoch 05 | Train=32.43% | Val=32.69% | ValLoss=1.3435\nEpoch 06 | Train=33.25% | Val=31.31% | ValLoss=1.3765\nEpoch 07 | Train=34.03% | Val=33.76% | ValLoss=1.3379\nEpoch 08 | Train=34.73% | Val=33.11% | ValLoss=1.3493\nEpoch 09 | Train=35.94% | Val=32.67% | ValLoss=1.3696\nEpoch 10 | Train=36.70% | Val=37.01% | ValLoss=1.3357\nEpoch 11 | Train=37.03% | Val=36.49% | ValLoss=1.3198\nEpoch 12 | Train=38.01% | Val=37.74% | ValLoss=1.3097\nEpoch 13 | Train=38.27% | Val=37.54% | ValLoss=1.3162\nEpoch 14 | Train=38.43% | Val=33.25% | ValLoss=1.3847\nEpoch 15 | Train=39.53% | Val=34.11% | ValLoss=1.3588\nEpoch 16 | Train=39.93% | Val=38.71% | ValLoss=1.2973\nEpoch 17 | Train=40.47% | Val=37.42% | ValLoss=1.3303\nEpoch 18 | Train=40.16% | Val=39.75% | ValLoss=1.2934\nEpoch 19 | Train=40.53% | Val=39.83% | ValLoss=1.2954\nEpoch 20 | Train=41.62% | Val=39.08% | ValLoss=1.2957\nEpoch 21 | Train=42.54% | Val=38.78% | ValLoss=1.3106\nEpoch 22 | Train=42.42% | Val=34.25% | ValLoss=1.3805\nEpoch 23 | Train=43.94% | Val=41.56% | ValLoss=1.2684\nEpoch 24 | Train=44.87% | Val=39.96% | ValLoss=1.2922\nEpoch 25 | Train=45.32% | Val=40.43% | ValLoss=1.2890\nEpoch 26 | Train=45.50% | Val=40.79% | ValLoss=1.2873\nEpoch 27 | Train=45.78% | Val=37.98% | ValLoss=1.3215\nEpoch 28 | Train=46.61% | Val=39.28% | ValLoss=1.2985\nEpoch 29 | Train=46.85% | Val=39.85% | ValLoss=1.2941\nEpoch 30 | Train=46.68% | Val=39.64% | ValLoss=1.2951\nEpoch 31 | Train=46.92% | Val=39.12% | ValLoss=1.3045\nEpoch 32 | Train=47.69% | Val=40.31% | ValLoss=1.2819\nEpoch 33 | Train=47.83% | Val=39.84% | ValLoss=1.2900\nEarly stopping (no improvement for 10 epochs).\nBest Accuracy (Fold 2): 41.56%\n\n----- Fold 3 -----\nInput : H = 62 W = 800\nAfter Conv1 :H = 62 W = 400\nAfter Conv2 :H = 62 W = 200\nAfter Conv3 :H = 62 W = 99\nAfter Conv4 :H = 62 W = 49\nAfter Conv5 :H = 62 W = 24\nAfter Flatten : torch.Size([16, 512, 1, 1])\nEpoch 01 | Train=28.31% | Val=31.82% | ValLoss=1.3708\nEpoch 02 | Train=30.11% | Val=31.12% | ValLoss=1.3650\nEpoch 03 | Train=30.10% | Val=32.31% | ValLoss=1.3532\nEpoch 04 | Train=31.46% | Val=31.07% | ValLoss=1.3604\nEpoch 05 | Train=32.04% | Val=31.32% | ValLoss=1.3865\nEpoch 06 | Train=32.24% | Val=33.17% | ValLoss=1.3501\nEpoch 07 | Train=32.88% | Val=33.04% | ValLoss=1.3478\nEpoch 08 | Train=33.27% | Val=30.82% | ValLoss=1.3622\nEpoch 09 | Train=34.09% | Val=33.61% | ValLoss=1.3619\nEpoch 10 | Train=35.57% | Val=30.79% | ValLoss=1.3569\nEpoch 11 | Train=35.94% | Val=36.59% | ValLoss=1.3216\nEpoch 12 | Train=36.78% | Val=36.18% | ValLoss=1.3268\nEpoch 13 | Train=37.42% | Val=36.75% | ValLoss=1.3069\nEpoch 14 | Train=37.91% | Val=37.68% | ValLoss=1.3472\nEpoch 15 | Train=38.29% | Val=38.70% | ValLoss=1.2979\nEpoch 16 | Train=39.85% | Val=39.51% | ValLoss=1.2906\nEpoch 17 | Train=40.16% | Val=39.28% | ValLoss=1.2913\nEpoch 18 | Train=40.47% | Val=38.91% | ValLoss=1.3474\nEpoch 19 | Train=40.44% | Val=40.60% | ValLoss=1.2860\nEpoch 20 | Train=40.85% | Val=40.24% | ValLoss=1.2922\nEpoch 21 | Train=41.26% | Val=39.77% | ValLoss=1.3046\nEpoch 22 | Train=41.53% | Val=38.56% | ValLoss=1.3383\nEpoch 23 | Train=41.72% | Val=40.69% | ValLoss=1.2903\nEpoch 24 | Train=43.77% | Val=42.18% | ValLoss=1.2618\nEpoch 25 | Train=44.52% | Val=42.70% | ValLoss=1.2632\nEpoch 26 | Train=44.40% | Val=42.16% | ValLoss=1.2653\nEpoch 27 | Train=45.06% | Val=41.64% | ValLoss=1.2867\nEpoch 28 | Train=45.26% | Val=42.37% | ValLoss=1.2666\nEpoch 29 | Train=45.97% | Val=42.50% | ValLoss=1.2690\nEpoch 30 | Train=46.86% | Val=42.49% | ValLoss=1.2755\nEpoch 31 | Train=46.74% | Val=42.20% | ValLoss=1.2803\nEpoch 32 | Train=46.81% | Val=42.24% | ValLoss=1.2746\nEpoch 33 | Train=46.86% | Val=43.02% | ValLoss=1.2646\nEpoch 34 | Train=46.48% | Val=42.85% | ValLoss=1.2640\nEpoch 35 | Train=47.21% | Val=42.05% | ValLoss=1.2741\nEpoch 36 | Train=47.33% | Val=42.93% | ValLoss=1.2651\nEpoch 37 | Train=46.94% | Val=42.57% | ValLoss=1.2719\nEpoch 38 | Train=47.24% | Val=42.90% | ValLoss=1.2704\nEpoch 39 | Train=47.36% | Val=42.63% | ValLoss=1.2697\nEpoch 40 | Train=47.02% | Val=42.53% | ValLoss=1.2717\nEpoch 41 | Train=47.49% | Val=42.29% | ValLoss=1.2788\nEpoch 42 | Train=47.19% | Val=42.25% | ValLoss=1.2714\nEpoch 43 | Train=47.20% | Val=42.32% | ValLoss=1.2813\nEarly stopping (no improvement for 10 epochs).\nBest Accuracy (Fold 3): 43.02%\n\n----- Fold 4 -----\nInput : H = 62 W = 800\nAfter Conv1 :H = 62 W = 400\nAfter Conv2 :H = 62 W = 200\nAfter Conv3 :H = 62 W = 99\nAfter Conv4 :H = 62 W = 49\nAfter Conv5 :H = 62 W = 24\nAfter Flatten : torch.Size([16, 512, 1, 1])\nEpoch 01 | Train=27.80% | Val=28.65% | ValLoss=1.3737\nEpoch 02 | Train=30.09% | Val=31.35% | ValLoss=1.3654\nEpoch 03 | Train=31.59% | Val=33.65% | ValLoss=1.3460\nEpoch 04 | Train=32.99% | Val=34.93% | ValLoss=1.3346\nEpoch 05 | Train=34.64% | Val=29.55% | ValLoss=1.3750\nEpoch 06 | Train=35.36% | Val=35.33% | ValLoss=1.3705\nEpoch 07 | Train=35.95% | Val=33.16% | ValLoss=1.3440\nEpoch 08 | Train=36.99% | Val=31.92% | ValLoss=1.3475\nEpoch 09 | Train=38.20% | Val=38.28% | ValLoss=1.3047\nEpoch 10 | Train=39.22% | Val=39.32% | ValLoss=1.2922\nEpoch 11 | Train=39.87% | Val=39.52% | ValLoss=1.2935\nEpoch 12 | Train=40.30% | Val=39.77% | ValLoss=1.2918\nEpoch 13 | Train=40.39% | Val=37.35% | ValLoss=1.3249\nEpoch 14 | Train=40.67% | Val=39.92% | ValLoss=1.3003\nEpoch 15 | Train=41.26% | Val=39.17% | ValLoss=1.3188\nEpoch 16 | Train=40.92% | Val=38.55% | ValLoss=1.3112\nEpoch 17 | Train=42.33% | Val=39.33% | ValLoss=1.2921\nEpoch 18 | Train=42.73% | Val=40.16% | ValLoss=1.2903\nEpoch 19 | Train=42.41% | Val=39.19% | ValLoss=1.3031\nEpoch 20 | Train=42.64% | Val=40.49% | ValLoss=1.2806\nEpoch 21 | Train=42.71% | Val=40.76% | ValLoss=1.2784\nEpoch 22 | Train=43.06% | Val=41.01% | ValLoss=1.2794\nEpoch 23 | Train=43.69% | Val=40.77% | ValLoss=1.2818\nEpoch 24 | Train=43.39% | Val=40.41% | ValLoss=1.2841\nEpoch 25 | Train=43.37% | Val=40.13% | ValLoss=1.2863\nEpoch 26 | Train=43.48% | Val=41.68% | ValLoss=1.2737\nEpoch 27 | Train=43.72% | Val=41.08% | ValLoss=1.2779\nEpoch 28 | Train=44.10% | Val=41.60% | ValLoss=1.2702\nEpoch 29 | Train=44.26% | Val=41.64% | ValLoss=1.2717\nEpoch 30 | Train=44.10% | Val=41.50% | ValLoss=1.2713\nEpoch 31 | Train=43.89% | Val=40.69% | ValLoss=1.2776\nEpoch 32 | Train=44.53% | Val=41.20% | ValLoss=1.2751\nEpoch 33 | Train=44.63% | Val=41.10% | ValLoss=1.2783\nEpoch 34 | Train=44.53% | Val=41.05% | ValLoss=1.2801\nEpoch 35 | Train=44.25% | Val=41.33% | ValLoss=1.2741\nEpoch 36 | Train=44.71% | Val=41.09% | ValLoss=1.2762\nEarly stopping (no improvement for 10 epochs).\nBest Accuracy (Fold 4): 41.68%\n\n----- Fold 5 -----\nInput : H = 62 W = 800\nAfter Conv1 :H = 62 W = 400\nAfter Conv2 :H = 62 W = 200\nAfter Conv3 :H = 62 W = 99\nAfter Conv4 :H = 62 W = 49\nAfter Conv5 :H = 62 W = 24\nAfter Flatten : torch.Size([16, 512, 1, 1])\nEpoch 01 | Train=28.69% | Val=29.14% | ValLoss=1.3775\nEpoch 02 | Train=30.34% | Val=28.25% | ValLoss=1.3763\nEpoch 03 | Train=31.97% | Val=26.83% | ValLoss=1.4107\nEpoch 04 | Train=32.92% | Val=31.30% | ValLoss=1.3673\nEpoch 05 | Train=32.92% | Val=32.92% | ValLoss=1.3456\nEpoch 06 | Train=34.42% | Val=34.52% | ValLoss=1.3386\nEpoch 07 | Train=35.36% | Val=35.78% | ValLoss=1.3339\nEpoch 08 | Train=36.36% | Val=36.39% | ValLoss=1.3242\nEpoch 09 | Train=36.50% | Val=30.98% | ValLoss=1.3771\nEpoch 10 | Train=37.20% | Val=34.68% | ValLoss=1.3832\nEpoch 11 | Train=37.95% | Val=33.55% | ValLoss=1.3782\nEpoch 12 | Train=38.75% | Val=37.68% | ValLoss=1.3186\nEpoch 13 | Train=39.46% | Val=35.58% | ValLoss=1.3441\nEpoch 14 | Train=39.30% | Val=38.43% | ValLoss=1.3117\nEpoch 15 | Train=40.24% | Val=37.94% | ValLoss=1.3130\nEpoch 16 | Train=40.57% | Val=37.78% | ValLoss=1.3206\nEpoch 17 | Train=40.79% | Val=38.62% | ValLoss=1.3036\nEpoch 18 | Train=41.45% | Val=34.96% | ValLoss=1.3593\nEpoch 19 | Train=41.11% | Val=36.83% | ValLoss=1.3415\nEpoch 20 | Train=41.42% | Val=36.99% | ValLoss=1.3094\nEpoch 21 | Train=41.98% | Val=39.12% | ValLoss=1.3003\nEpoch 22 | Train=42.34% | Val=39.89% | ValLoss=1.2878\nEpoch 23 | Train=42.84% | Val=39.40% | ValLoss=1.3071\nEpoch 24 | Train=43.20% | Val=38.68% | ValLoss=1.3249\nEpoch 25 | Train=43.26% | Val=41.10% | ValLoss=1.2804\nEpoch 26 | Train=43.78% | Val=38.95% | ValLoss=1.3054\nEpoch 27 | Train=43.86% | Val=36.93% | ValLoss=1.3366\nEpoch 28 | Train=44.42% | Val=41.12% | ValLoss=1.2726\nEpoch 29 | Train=44.71% | Val=40.98% | ValLoss=1.2975\nEpoch 30 | Train=45.41% | Val=33.68% | ValLoss=1.4633\nEpoch 31 | Train=45.26% | Val=38.46% | ValLoss=1.3185\nEpoch 32 | Train=45.95% | Val=40.75% | ValLoss=1.2896\nEpoch 33 | Train=47.78% | Val=39.52% | ValLoss=1.3136\nEpoch 34 | Train=48.91% | Val=39.61% | ValLoss=1.3131\nEpoch 35 | Train=49.55% | Val=39.84% | ValLoss=1.3043\nEpoch 36 | Train=49.75% | Val=41.76% | ValLoss=1.2839\nEpoch 37 | Train=50.59% | Val=42.18% | ValLoss=1.2786\nEpoch 38 | Train=50.99% | Val=40.60% | ValLoss=1.3048\nEpoch 39 | Train=51.12% | Val=40.68% | ValLoss=1.3104\nEpoch 40 | Train=50.48% | Val=41.20% | ValLoss=1.2889\nEpoch 41 | Train=50.55% | Val=41.30% | ValLoss=1.2888\nEpoch 42 | Train=50.91% | Val=40.59% | ValLoss=1.2999\nEpoch 43 | Train=50.81% | Val=40.96% | ValLoss=1.2952\nEpoch 44 | Train=51.06% | Val=40.96% | ValLoss=1.2873\nEpoch 45 | Train=51.96% | Val=40.79% | ValLoss=1.2963\nEpoch 46 | Train=51.22% | Val=40.63% | ValLoss=1.2934\nEpoch 47 | Train=51.66% | Val=40.45% | ValLoss=1.3046\nEarly stopping (no improvement for 10 epochs).\nBest Accuracy (Fold 5): 42.18%\n\n========== Final Cross‚ÄëValidation Results ==========\nFold 1: 42.82%\nFold 2: 41.56%\nFold 3: 43.02%\nFold 4: 41.68%\nFold 5: 42.18%\n\nAverage Accuracy = 42.25149700598803\n","output_type":"stream"}],"execution_count":23}]}