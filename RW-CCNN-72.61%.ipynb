{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rawanmoamed/eeg-classification-ccnn?scriptVersionId=285440418\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"95d21310","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-12-11T13:45:48.818365Z","iopub.status.busy":"2025-12-11T13:45:48.818105Z","iopub.status.idle":"2025-12-11T13:59:59.226367Z","shell.execute_reply":"2025-12-11T13:59:59.225547Z"},"papermill":{"duration":850.413571,"end_time":"2025-12-11T13:59:59.227806","exception":false,"start_time":"2025-12-11T13:45:48.814235","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m231.5/231.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.1/295.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m750.2/750.2 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","kaggle-environments 1.18.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\r\n","cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n","jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\r\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\r\n","dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n","scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\r\n","libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n","cvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\r\n","imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n","xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\r\n","plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n","jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\r\n","umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n","mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0m"]}],"source":["!pip install torch_scatter torcheeg torch_geometric -qq"]},{"cell_type":"code","execution_count":2,"id":"cb564a80","metadata":{"execution":{"iopub.execute_input":"2025-12-11T13:59:59.270301Z","iopub.status.busy":"2025-12-11T13:59:59.269691Z","iopub.status.idle":"2025-12-11T14:00:12.005688Z","shell.execute_reply":"2025-12-11T14:00:12.004768Z"},"papermill":{"duration":12.75879,"end_time":"2025-12-11T14:00:12.007234","exception":false,"start_time":"2025-12-11T13:59:59.248444","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.utils as utils\n","from torch.utils.data import DataLoader, Subset,WeightedRandomSampler\n","from torcheeg.models import CCNN\n","from torcheeg import transforms\n","from torcheeg.transforms import ToGrid\n","from torcheeg.datasets import SEEDIVDataset,SEEDIVFeatureDataset\n","from torcheeg.datasets.constants import SEED_IV_CHANNEL_LOCATION_DICT\n","from torcheeg.transforms import ToG\n","from torcheeg.datasets.constants import SEED_IV_ADJACENCY_MATRIX\n","from torcheeg.models import DGCNN\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.optim.lr_scheduler import ReduceLROnPlateau \n","# --- THE MAIN SUBJECT LOOP ---\n","\n","import torch_geometric.loader as geom_loader # Special loader for graphs\n","import copy\n","import scipy.signal as signal\n","import random\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"id":"e7db79d8","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:00:12.049453Z","iopub.status.busy":"2025-12-11T14:00:12.048908Z","iopub.status.idle":"2025-12-11T14:00:12.053039Z","shell.execute_reply":"2025-12-11T14:00:12.052458Z"},"papermill":{"duration":0.026086,"end_time":"2025-12-11T14:00:12.054138","exception":false,"start_time":"2025-12-11T14:00:12.028052","status":"completed"},"tags":[]},"outputs":[],"source":["import shutil\n","import os\n","\n","if os.path.exists('./tmp_out/seed_iv_features'):\n","    shutil.rmtree('./tmp_out/seed_iv_features')\n","    print(\"Old cache deleted. Data will be re-processed.\")"]},{"cell_type":"code","execution_count":4,"id":"b7d92d50","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:00:12.094768Z","iopub.status.busy":"2025-12-11T14:00:12.09453Z","iopub.status.idle":"2025-12-11T14:00:12.097856Z","shell.execute_reply":"2025-12-11T14:00:12.097286Z"},"papermill":{"duration":0.025028,"end_time":"2025-12-11T14:00:12.098926","exception":false,"start_time":"2025-12-11T14:00:12.073898","status":"completed"},"tags":[]},"outputs":[],"source":["# 1. Setup Device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"id":"b6e81331","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:00:12.139846Z","iopub.status.busy":"2025-12-11T14:00:12.139616Z","iopub.status.idle":"2025-12-11T14:03:10.022818Z","shell.execute_reply":"2025-12-11T14:03:10.02218Z"},"papermill":{"duration":177.905191,"end_time":"2025-12-11T14:03:10.024367","exception":false,"start_time":"2025-12-11T14:00:12.119176","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[2025-12-11 14:00:12] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m./tmp_out/seed_iv_features\u001b[0m.\n","[2025-12-11 14:00:12] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n","[PROCESS]:   0%|          | 0/45 [00:00<?, ?it/s]\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 0it [00:00, ?it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 3it [00:00, 29.67it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 23it [00:00, 127.96it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 42it [00:00, 152.38it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 63it [00:00, 173.82it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 84it [00:00, 185.80it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 105it [00:00, 191.06it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 125it [00:00, 185.20it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 144it [00:00, 180.85it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 163it [00:00, 177.92it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 181it [00:01, 177.77it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 200it [00:01, 179.72it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 221it [00:01, 186.68it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 240it [00:01, 186.16it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 262it [00:01, 194.83it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 284it [00:01, 199.48it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 305it [00:01, 202.35it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 326it [00:01, 199.96it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 347it [00:01, 199.46it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 367it [00:01, 199.06it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 387it [00:02, 199.01it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 407it [00:02, 198.01it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 427it [00:02, 192.01it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 448it [00:02, 196.43it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 469it [00:02, 199.63it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 490it [00:02, 201.35it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 511it [00:02, 200.07it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 532it [00:02, 197.52it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 552it [00:02, 195.57it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 572it [00:03, 194.04it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 592it [00:03, 194.93it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 613it [00:03, 199.20it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 636it [00:03, 205.94it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 659it [00:03, 211.10it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 681it [00:03, 209.22it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 702it [00:03, 203.22it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 723it [00:03, 190.43it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 743it [00:03, 179.98it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 762it [00:04, 174.08it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 780it [00:04, 172.98it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 798it [00:04, 166.65it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 815it [00:04, 165.65it/s]\u001b[A\n","[RECORD /kaggle/input/seed-iv/eeg_feature_smooth/1/4_20151111.mat]: 835it [00:04, 174.70it/s]\u001b[A\n","[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [02:57<00:00,  3.95s/it]\n","[2025-12-11 14:03:09] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to ./tmp_out/seed_iv_features.\n","[2025-12-11 14:03:09] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m./tmp_out/seed_iv_features\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"]}],"source":["from torcheeg.datasets.constants import SEED_IV_CHANNEL_LOCATION_DICT\n","from torcheeg.transforms import ToGrid\n","\n","dataset = SEEDIVFeatureDataset(\n","    io_path='./tmp_out/seed_iv_features',\n","    root_path='/kaggle/input/seed-iv/eeg_feature_smooth',\n","    feature=['de_LDS'],\n","    num_worker=0,\n","    offline_transform=transforms.Compose([\n","        ToGrid(SEED_IV_CHANNEL_LOCATION_DICT),\n","        transforms.MinMaxNormalize(),\n","        transforms.Lambda(lambda x: torch.tensor(x).float())\n","        \n","    ]),\n","    label_transform=transforms.Compose([\n","        transforms.Select('emotion')\n","    ])\n",")\n"]},{"cell_type":"code","execution_count":6,"id":"0873dc23","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:03:10.083284Z","iopub.status.busy":"2025-12-11T14:03:10.082483Z","iopub.status.idle":"2025-12-11T14:03:10.091125Z","shell.execute_reply":"2025-12-11T14:03:10.090602Z"},"papermill":{"duration":0.038435,"end_time":"2025-12-11T14:03:10.092131","exception":false,"start_time":"2025-12-11T14:03:10.053696","status":"completed"},"tags":[]},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(42) "]},{"cell_type":"code","execution_count":7,"id":"b8176acc","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:03:10.149598Z","iopub.status.busy":"2025-12-11T14:03:10.148822Z","iopub.status.idle":"2025-12-11T14:03:10.155097Z","shell.execute_reply":"2025-12-11T14:03:10.154381Z"},"papermill":{"duration":0.036179,"end_time":"2025-12-11T14:03:10.156187","exception":false,"start_time":"2025-12-11T14:03:10.120008","status":"completed"},"tags":[]},"outputs":[],"source":["subjects = sorted(dataset.info['subject_id'].unique()) # Get list of all 15 subjects"]},{"cell_type":"code","execution_count":8,"id":"93c2a033","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:03:10.215523Z","iopub.status.busy":"2025-12-11T14:03:10.215062Z","iopub.status.idle":"2025-12-11T14:03:10.219068Z","shell.execute_reply":"2025-12-11T14:03:10.218546Z"},"papermill":{"duration":0.035641,"end_time":"2025-12-11T14:03:10.220049","exception":false,"start_time":"2025-12-11T14:03:10.184408","status":"completed"},"tags":[]},"outputs":[],"source":["def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if m.bias is not None:\n","            nn.init.constant_(m.bias, 0)"]},{"cell_type":"code","execution_count":9,"id":"f6edf215","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:03:10.277313Z","iopub.status.busy":"2025-12-11T14:03:10.276823Z","iopub.status.idle":"2025-12-11T14:03:10.281787Z","shell.execute_reply":"2025-12-11T14:03:10.281186Z"},"papermill":{"duration":0.034812,"end_time":"2025-12-11T14:03:10.282796","exception":false,"start_time":"2025-12-11T14:03:10.247984","status":"completed"},"tags":[]},"outputs":[],"source":["def train_one_epoch(model, loader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch in loader:\n","        x = batch[0].to(device)\n","        y = batch[1].to(device)\n","\n","\n","        optimizer.zero_grad()\n","        out = model(x)\n","        loss = criterion(out, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        preds = out.argmax(dim=1)\n","        correct += (preds == y).sum().item()\n","        total += y.size(0)\n","\n","    return total_loss / len(loader), correct / total"]},{"cell_type":"code","execution_count":10,"id":"42e0b4f4","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:03:10.338983Z","iopub.status.busy":"2025-12-11T14:03:10.338461Z","iopub.status.idle":"2025-12-11T14:03:10.343208Z","shell.execute_reply":"2025-12-11T14:03:10.34267Z"},"papermill":{"duration":0.03404,"end_time":"2025-12-11T14:03:10.344255","exception":false,"start_time":"2025-12-11T14:03:10.310215","status":"completed"},"tags":[]},"outputs":[],"source":["def evaluate(model, loader, criterion):\n","    model.eval()\n","    \n","    total_loss = 0.0  \n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch in loader:\n","            x = batch[0].to(device)\n","            y = batch[1].to(device)\n","\n","            out = model(x)\n","            \n","            loss = criterion(out, y)\n","            total_loss += loss.item()\n","\n","            preds = out.argmax(dim=1)\n","            correct += (preds == y).sum().item()\n","            total += y.size(0)\n","\n","    return total_loss / len(loader), correct / total"]},{"cell_type":"code","execution_count":11,"id":"bcaf9ab2","metadata":{"execution":{"iopub.execute_input":"2025-12-11T14:03:10.401053Z","iopub.status.busy":"2025-12-11T14:03:10.400835Z","iopub.status.idle":"2025-12-11T14:25:41.128203Z","shell.execute_reply":"2025-12-11T14:25:41.127451Z"},"papermill":{"duration":1350.757276,"end_time":"2025-12-11T14:25:41.129355","exception":false,"start_time":"2025-12-11T14:03:10.372079","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Processing SUBJECT: 1\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n","  warnings.warn(warn_msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100 | Train Loss: 6.4076 | Val Loss: 1.3122 | Train Acc: 0.249 | Val Acc: 0.382 (*) BEST\n","Epoch 4/100 | Train Loss: 1.4108 | Val Loss: 1.3186 | Train Acc: 0.340 | Val Acc: 0.425 (*) BEST\n","Epoch 10/100 | Train Loss: 1.2047 | Val Loss: 1.4381 | Train Acc: 0.445 | Val Acc: 0.279 \n","Epoch 11/100 | Train Loss: 1.1195 | Val Loss: 1.3582 | Train Acc: 0.531 | Val Acc: 0.487 (*) BEST\n","Epoch 20/100 | Train Loss: 1.0412 | Val Loss: 1.4605 | Train Acc: 0.556 | Val Acc: 0.430 \n","Epoch 24/100 | Train Loss: 0.8915 | Val Loss: 1.2909 | Train Acc: 0.682 | Val Acc: 0.546 (*) BEST\n","Epoch 30/100 | Train Loss: 0.8012 | Val Loss: 1.3884 | Train Acc: 0.711 | Val Acc: 0.414 \n","Epoch 40/100 | Train Loss: 0.7028 | Val Loss: 1.0467 | Train Acc: 0.738 | Val Acc: 0.507 \n","Epoch 50/100 | Train Loss: 0.5035 | Val Loss: 1.6109 | Train Acc: 0.860 | Val Acc: 0.406 \n","Epoch 53/100 | Train Loss: 0.5193 | Val Loss: 1.0556 | Train Acc: 0.844 | Val Acc: 0.619 (*) BEST\n","Epoch 60/100 | Train Loss: 0.4319 | Val Loss: 1.1954 | Train Acc: 0.891 | Val Acc: 0.421 \n","Epoch 70/100 | Train Loss: 0.3393 | Val Loss: 1.1599 | Train Acc: 0.934 | Val Acc: 0.377 \n","Epoch 80/100 | Train Loss: 0.3075 | Val Loss: 1.2711 | Train Acc: 0.954 | Val Acc: 0.395 \n","Epoch 90/100 | Train Loss: 0.2880 | Val Loss: 1.0730 | Train Acc: 0.948 | Val Acc: 0.428 \n","Epoch 100/100 | Train Loss: 0.2891 | Val Loss: 1.0846 | Train Acc: 0.959 | Val Acc: 0.428 \n","Subject 1 FINAL BEST ACC: 61.95%\n","\n","Processing SUBJECT: 2\n","Epoch 1/100 | Train Loss: 6.8261 | Val Loss: 1.4132 | Train Acc: 0.276 | Val Acc: 0.463 (*) BEST\n","Epoch 5/100 | Train Loss: 0.9574 | Val Loss: 1.3869 | Train Acc: 0.589 | Val Acc: 0.491 (*) BEST\n","Epoch 7/100 | Train Loss: 0.7493 | Val Loss: 1.3603 | Train Acc: 0.711 | Val Acc: 0.596 (*) BEST\n","Epoch 10/100 | Train Loss: 0.6373 | Val Loss: 1.1553 | Train Acc: 0.778 | Val Acc: 0.533 \n","Epoch 11/100 | Train Loss: 0.5522 | Val Loss: 1.3871 | Train Acc: 0.825 | Val Acc: 0.603 (*) BEST\n","Epoch 19/100 | Train Loss: 0.2995 | Val Loss: 1.1434 | Train Acc: 0.933 | Val Acc: 0.680 (*) BEST\n","Epoch 20/100 | Train Loss: 0.3600 | Val Loss: 1.3079 | Train Acc: 0.878 | Val Acc: 0.551 \n","Epoch 26/100 | Train Loss: 0.4399 | Val Loss: 1.2754 | Train Acc: 0.831 | Val Acc: 0.715 (*) BEST\n","Epoch 29/100 | Train Loss: 0.2383 | Val Loss: 1.2184 | Train Acc: 0.934 | Val Acc: 0.726 (*) BEST\n","Epoch 30/100 | Train Loss: 0.2234 | Val Loss: 1.2831 | Train Acc: 0.927 | Val Acc: 0.546 \n","Epoch 34/100 | Train Loss: 0.1589 | Val Loss: 1.2703 | Train Acc: 0.968 | Val Acc: 0.763 (*) BEST\n","Epoch 40/100 | Train Loss: 0.1189 | Val Loss: 1.4919 | Train Acc: 0.976 | Val Acc: 0.715 \n","Epoch 41/100 | Train Loss: 0.1490 | Val Loss: 1.3272 | Train Acc: 0.972 | Val Acc: 0.767 (*) BEST\n","Epoch 50/100 | Train Loss: 0.1006 | Val Loss: 1.3870 | Train Acc: 0.977 | Val Acc: 0.715 \n","Epoch 52/100 | Train Loss: 0.0770 | Val Loss: 1.4097 | Train Acc: 0.990 | Val Acc: 0.781 (*) BEST\n","Epoch 60/100 | Train Loss: 0.0630 | Val Loss: 1.4699 | Train Acc: 0.990 | Val Acc: 0.719 \n","Epoch 70/100 | Train Loss: 0.0467 | Val Loss: 1.3857 | Train Acc: 0.994 | Val Acc: 0.675 \n","Epoch 80/100 | Train Loss: 0.0322 | Val Loss: 1.4953 | Train Acc: 0.997 | Val Acc: 0.730 \n","Epoch 90/100 | Train Loss: 0.0333 | Val Loss: 1.5660 | Train Acc: 0.996 | Val Acc: 0.781 \n","Epoch 100/100 | Train Loss: 0.0315 | Val Loss: 1.5509 | Train Acc: 0.998 | Val Acc: 0.781 \n","Subject 2 FINAL BEST ACC: 78.12%\n","\n","Processing SUBJECT: 3\n","Epoch 1/100 | Train Loss: 7.7816 | Val Loss: 1.6749 | Train Acc: 0.263 | Val Acc: 0.112 (*) BEST\n","Epoch 2/100 | Train Loss: 1.5055 | Val Loss: 1.4467 | Train Acc: 0.277 | Val Acc: 0.184 (*) BEST\n","Epoch 3/100 | Train Loss: 1.3833 | Val Loss: 1.4052 | Train Acc: 0.335 | Val Acc: 0.399 (*) BEST\n","Epoch 10/100 | Train Loss: 1.2308 | Val Loss: 1.4245 | Train Acc: 0.428 | Val Acc: 0.381 \n","Epoch 15/100 | Train Loss: 1.1575 | Val Loss: 1.3235 | Train Acc: 0.491 | Val Acc: 0.425 (*) BEST\n","Epoch 16/100 | Train Loss: 1.1178 | Val Loss: 1.1589 | Train Acc: 0.540 | Val Acc: 0.483 (*) BEST\n","Epoch 20/100 | Train Loss: 1.0874 | Val Loss: 1.2888 | Train Acc: 0.558 | Val Acc: 0.347 \n","Epoch 30/100 | Train Loss: 0.9371 | Val Loss: 1.2989 | Train Acc: 0.620 | Val Acc: 0.452 \n","Epoch 36/100 | Train Loss: 0.7640 | Val Loss: 1.1042 | Train Acc: 0.727 | Val Acc: 0.504 (*) BEST\n","Epoch 40/100 | Train Loss: 0.7065 | Val Loss: 1.2803 | Train Acc: 0.743 | Val Acc: 0.338 \n","Epoch 42/100 | Train Loss: 0.6664 | Val Loss: 0.9732 | Train Acc: 0.774 | Val Acc: 0.572 (*) BEST\n","Epoch 45/100 | Train Loss: 0.6727 | Val Loss: 1.0193 | Train Acc: 0.751 | Val Acc: 0.579 (*) BEST\n","Epoch 46/100 | Train Loss: 0.6457 | Val Loss: 0.8824 | Train Acc: 0.779 | Val Acc: 0.654 (*) BEST\n","Epoch 50/100 | Train Loss: 0.5468 | Val Loss: 0.9615 | Train Acc: 0.840 | Val Acc: 0.482 \n","Epoch 60/100 | Train Loss: 0.5471 | Val Loss: 0.9162 | Train Acc: 0.799 | Val Acc: 0.564 \n","Epoch 61/100 | Train Loss: 0.4878 | Val Loss: 0.8027 | Train Acc: 0.857 | Val Acc: 0.676 (*) BEST\n","Epoch 66/100 | Train Loss: 0.4249 | Val Loss: 0.8206 | Train Acc: 0.886 | Val Acc: 0.689 (*) BEST\n","Epoch 70/100 | Train Loss: 0.3972 | Val Loss: 0.8246 | Train Acc: 0.899 | Val Acc: 0.564 \n","Epoch 74/100 | Train Loss: 0.3655 | Val Loss: 0.7450 | Train Acc: 0.911 | Val Acc: 0.778 (*) BEST\n","Epoch 80/100 | Train Loss: 0.3631 | Val Loss: 0.7946 | Train Acc: 0.917 | Val Acc: 0.673 \n","Epoch 90/100 | Train Loss: 0.3452 | Val Loss: 0.7470 | Train Acc: 0.935 | Val Acc: 0.689 \n","Epoch 100/100 | Train Loss: 0.3399 | Val Loss: 0.7758 | Train Acc: 0.941 | Val Acc: 0.689 \n","Subject 3 FINAL BEST ACC: 77.76%\n","\n","Processing SUBJECT: 4\n","Epoch 1/100 | Train Loss: 6.1342 | Val Loss: 1.1984 | Train Acc: 0.263 | Val Acc: 0.449 (*) BEST\n","Epoch 3/100 | Train Loss: 1.2666 | Val Loss: 1.0573 | Train Acc: 0.427 | Val Acc: 0.625 (*) BEST\n","Epoch 10/100 | Train Loss: 0.8955 | Val Loss: 1.3514 | Train Acc: 0.637 | Val Acc: 0.184 \n","Epoch 15/100 | Train Loss: 0.7394 | Val Loss: 0.8263 | Train Acc: 0.704 | Val Acc: 0.662 (*) BEST\n","Epoch 17/100 | Train Loss: 0.6383 | Val Loss: 0.7326 | Train Acc: 0.762 | Val Acc: 0.697 (*) BEST\n","Epoch 19/100 | Train Loss: 0.6863 | Val Loss: 0.7030 | Train Acc: 0.735 | Val Acc: 0.744 (*) BEST\n","Epoch 20/100 | Train Loss: 0.5522 | Val Loss: 0.7625 | Train Acc: 0.808 | Val Acc: 0.757 (*) BEST\n","Epoch 22/100 | Train Loss: 0.5060 | Val Loss: 0.7936 | Train Acc: 0.844 | Val Acc: 0.763 (*) BEST\n","Epoch 27/100 | Train Loss: 0.3961 | Val Loss: 0.6365 | Train Acc: 0.886 | Val Acc: 0.774 (*) BEST\n","Epoch 30/100 | Train Loss: 0.3954 | Val Loss: 0.9607 | Train Acc: 0.877 | Val Acc: 0.498 \n","Epoch 40/100 | Train Loss: 0.2474 | Val Loss: 0.4951 | Train Acc: 0.943 | Val Acc: 0.744 \n","Epoch 48/100 | Train Loss: 0.1464 | Val Loss: 0.4979 | Train Acc: 0.987 | Val Acc: 0.801 (*) BEST\n","Epoch 50/100 | Train Loss: 0.1540 | Val Loss: 0.4681 | Train Acc: 0.984 | Val Acc: 0.763 \n","Epoch 60/100 | Train Loss: 0.0904 | Val Loss: 0.5110 | Train Acc: 0.995 | Val Acc: 0.763 \n","Epoch 70/100 | Train Loss: 0.0785 | Val Loss: 0.5000 | Train Acc: 0.995 | Val Acc: 0.763 \n","Epoch 80/100 | Train Loss: 0.0691 | Val Loss: 0.5313 | Train Acc: 0.993 | Val Acc: 0.763 \n","Epoch 90/100 | Train Loss: 0.0553 | Val Loss: 0.5288 | Train Acc: 0.997 | Val Acc: 0.763 \n","Epoch 100/100 | Train Loss: 0.0568 | Val Loss: 0.5751 | Train Acc: 0.997 | Val Acc: 0.763 \n","Subject 4 FINAL BEST ACC: 80.15%\n","\n","Processing SUBJECT: 5\n","Epoch 1/100 | Train Loss: 7.6975 | Val Loss: 1.9442 | Train Acc: 0.267 | Val Acc: 0.173 (*) BEST\n","Epoch 2/100 | Train Loss: 1.6551 | Val Loss: 1.4877 | Train Acc: 0.286 | Val Acc: 0.320 (*) BEST\n","Epoch 4/100 | Train Loss: 1.3064 | Val Loss: 1.4310 | Train Acc: 0.399 | Val Acc: 0.371 (*) BEST\n","Epoch 5/100 | Train Loss: 1.2896 | Val Loss: 1.4321 | Train Acc: 0.404 | Val Acc: 0.382 (*) BEST\n","Epoch 7/100 | Train Loss: 1.2189 | Val Loss: 1.2970 | Train Acc: 0.451 | Val Acc: 0.412 (*) BEST\n","Epoch 10/100 | Train Loss: 1.0894 | Val Loss: 1.2737 | Train Acc: 0.536 | Val Acc: 0.417 (*) BEST\n","Epoch 17/100 | Train Loss: 0.9686 | Val Loss: 1.1612 | Train Acc: 0.607 | Val Acc: 0.559 (*) BEST\n","Epoch 20/100 | Train Loss: 0.8515 | Val Loss: 1.2105 | Train Acc: 0.697 | Val Acc: 0.215 \n","Epoch 30/100 | Train Loss: 0.7560 | Val Loss: 1.3829 | Train Acc: 0.705 | Val Acc: 0.463 \n","Epoch 40/100 | Train Loss: 0.6045 | Val Loss: 1.0734 | Train Acc: 0.767 | Val Acc: 0.355 \n","Epoch 50/100 | Train Loss: 0.4379 | Val Loss: 1.2353 | Train Acc: 0.873 | Val Acc: 0.471 \n","Epoch 60/100 | Train Loss: 0.3613 | Val Loss: 0.9931 | Train Acc: 0.906 | Val Acc: 0.551 \n","Epoch 64/100 | Train Loss: 0.3546 | Val Loss: 1.1114 | Train Acc: 0.906 | Val Acc: 0.612 (*) BEST\n","Epoch 70/100 | Train Loss: 0.2977 | Val Loss: 0.9999 | Train Acc: 0.922 | Val Acc: 0.518 \n","Epoch 79/100 | Train Loss: 0.2814 | Val Loss: 1.0584 | Train Acc: 0.939 | Val Acc: 0.631 (*) BEST\n","Epoch 80/100 | Train Loss: 0.2905 | Val Loss: 0.9947 | Train Acc: 0.936 | Val Acc: 0.507 \n","Epoch 90/100 | Train Loss: 0.2558 | Val Loss: 1.0079 | Train Acc: 0.955 | Val Acc: 0.597 \n","Epoch 100/100 | Train Loss: 0.2670 | Val Loss: 0.9549 | Train Acc: 0.951 | Val Acc: 0.476 \n","Subject 5 FINAL BEST ACC: 63.05%\n","\n","Processing SUBJECT: 6\n","Epoch 1/100 | Train Loss: 5.7275 | Val Loss: 1.5113 | Train Acc: 0.267 | Val Acc: 0.125 (*) BEST\n","Epoch 2/100 | Train Loss: 1.4671 | Val Loss: 1.2755 | Train Acc: 0.304 | Val Acc: 0.480 (*) BEST\n","Epoch 6/100 | Train Loss: 1.1184 | Val Loss: 1.2377 | Train Acc: 0.534 | Val Acc: 0.531 (*) BEST\n","Epoch 8/100 | Train Loss: 0.9685 | Val Loss: 1.0968 | Train Acc: 0.642 | Val Acc: 0.540 (*) BEST\n","Epoch 10/100 | Train Loss: 1.0309 | Val Loss: 1.1090 | Train Acc: 0.566 | Val Acc: 0.507 \n","Epoch 19/100 | Train Loss: 0.6330 | Val Loss: 1.0807 | Train Acc: 0.772 | Val Acc: 0.568 (*) BEST\n","Epoch 20/100 | Train Loss: 0.6062 | Val Loss: 1.3490 | Train Acc: 0.780 | Val Acc: 0.369 \n","Epoch 23/100 | Train Loss: 0.5900 | Val Loss: 0.8974 | Train Acc: 0.773 | Val Acc: 0.653 (*) BEST\n","Epoch 30/100 | Train Loss: 0.4660 | Val Loss: 1.0716 | Train Acc: 0.839 | Val Acc: 0.562 \n","Epoch 37/100 | Train Loss: 0.3277 | Val Loss: 0.7856 | Train Acc: 0.909 | Val Acc: 0.682 (*) BEST\n","Epoch 40/100 | Train Loss: 0.3061 | Val Loss: 0.8871 | Train Acc: 0.926 | Val Acc: 0.585 \n","Epoch 43/100 | Train Loss: 0.2956 | Val Loss: 0.7935 | Train Acc: 0.927 | Val Acc: 0.702 (*) BEST\n","Epoch 50/100 | Train Loss: 0.2295 | Val Loss: 1.1244 | Train Acc: 0.950 | Val Acc: 0.562 \n","Epoch 60/100 | Train Loss: 0.1763 | Val Loss: 0.8334 | Train Acc: 0.967 | Val Acc: 0.616 \n","Epoch 70/100 | Train Loss: 0.1318 | Val Loss: 1.0176 | Train Acc: 0.979 | Val Acc: 0.612 \n","Epoch 80/100 | Train Loss: 0.1080 | Val Loss: 1.0936 | Train Acc: 0.984 | Val Acc: 0.610 \n","Epoch 90/100 | Train Loss: 0.1050 | Val Loss: 1.0320 | Train Acc: 0.982 | Val Acc: 0.610 \n","Epoch 100/100 | Train Loss: 0.0964 | Val Loss: 1.0242 | Train Acc: 0.987 | Val Acc: 0.610 \n","Subject 6 FINAL BEST ACC: 70.22%\n","\n","Processing SUBJECT: 7\n","Epoch 1/100 | Train Loss: 7.3193 | Val Loss: 2.8717 | Train Acc: 0.268 | Val Acc: 0.173 (*) BEST\n","Epoch 2/100 | Train Loss: 1.8647 | Val Loss: 1.1927 | Train Acc: 0.286 | Val Acc: 0.425 (*) BEST\n","Epoch 5/100 | Train Loss: 1.1790 | Val Loss: 1.1041 | Train Acc: 0.465 | Val Acc: 0.642 (*) BEST\n","Epoch 10/100 | Train Loss: 1.0478 | Val Loss: 1.2314 | Train Acc: 0.561 | Val Acc: 0.493 \n","Epoch 18/100 | Train Loss: 0.8123 | Val Loss: 0.8945 | Train Acc: 0.737 | Val Acc: 0.697 (*) BEST\n","Epoch 20/100 | Train Loss: 0.7442 | Val Loss: 0.9642 | Train Acc: 0.773 | Val Acc: 0.634 \n","Epoch 24/100 | Train Loss: 0.7086 | Val Loss: 0.8036 | Train Acc: 0.760 | Val Acc: 0.765 (*) BEST\n","Epoch 30/100 | Train Loss: 0.6154 | Val Loss: 0.9658 | Train Acc: 0.799 | Val Acc: 0.467 \n","Epoch 40/100 | Train Loss: 0.4662 | Val Loss: 0.6367 | Train Acc: 0.859 | Val Acc: 0.632 \n","Epoch 46/100 | Train Loss: 0.3671 | Val Loss: 0.5305 | Train Acc: 0.907 | Val Acc: 0.789 (*) BEST\n","Epoch 49/100 | Train Loss: 0.3182 | Val Loss: 0.6222 | Train Acc: 0.927 | Val Acc: 0.798 (*) BEST\n","Epoch 50/100 | Train Loss: 0.3343 | Val Loss: 0.5564 | Train Acc: 0.913 | Val Acc: 0.822 (*) BEST\n","Epoch 59/100 | Train Loss: 0.2650 | Val Loss: 0.4989 | Train Acc: 0.937 | Val Acc: 0.869 (*) BEST\n","Epoch 60/100 | Train Loss: 0.2733 | Val Loss: 0.4511 | Train Acc: 0.925 | Val Acc: 0.881 (*) BEST\n","Epoch 70/100 | Train Loss: 0.2342 | Val Loss: 0.4986 | Train Acc: 0.950 | Val Acc: 0.803 \n","Epoch 80/100 | Train Loss: 0.1870 | Val Loss: 0.4500 | Train Acc: 0.967 | Val Acc: 0.847 \n","Epoch 90/100 | Train Loss: 0.1716 | Val Loss: 0.4010 | Train Acc: 0.975 | Val Acc: 0.869 \n","Epoch 100/100 | Train Loss: 0.1733 | Val Loss: 0.4452 | Train Acc: 0.970 | Val Acc: 0.847 \n","Subject 7 FINAL BEST ACC: 88.05%\n","\n","Processing SUBJECT: 8\n","Epoch 1/100 | Train Loss: 8.6731 | Val Loss: 2.2081 | Train Acc: 0.231 | Val Acc: 0.382 (*) BEST\n","Epoch 10/100 | Train Loss: 1.0782 | Val Loss: 1.2663 | Train Acc: 0.549 | Val Acc: 0.494 (*) BEST\n","Epoch 20/100 | Train Loss: 0.8948 | Val Loss: 1.3405 | Train Acc: 0.616 | Val Acc: 0.467 \n","Epoch 30/100 | Train Loss: 0.6688 | Val Loss: 1.2572 | Train Acc: 0.755 | Val Acc: 0.434 \n","Epoch 34/100 | Train Loss: 0.6656 | Val Loss: 1.0929 | Train Acc: 0.737 | Val Acc: 0.619 (*) BEST\n","Epoch 40/100 | Train Loss: 0.5072 | Val Loss: 1.2189 | Train Acc: 0.832 | Val Acc: 0.531 \n","Epoch 50/100 | Train Loss: 0.4296 | Val Loss: 0.9107 | Train Acc: 0.842 | Val Acc: 0.651 (*) BEST\n","Epoch 53/100 | Train Loss: 0.3761 | Val Loss: 0.9555 | Train Acc: 0.892 | Val Acc: 0.695 (*) BEST\n","Epoch 60/100 | Train Loss: 0.3056 | Val Loss: 1.0279 | Train Acc: 0.941 | Val Acc: 0.710 (*) BEST\n","Epoch 70/100 | Train Loss: 0.2626 | Val Loss: 0.9589 | Train Acc: 0.954 | Val Acc: 0.634 \n","Epoch 80/100 | Train Loss: 0.2346 | Val Loss: 1.0862 | Train Acc: 0.969 | Val Acc: 0.575 \n","Epoch 90/100 | Train Loss: 0.2142 | Val Loss: 1.0610 | Train Acc: 0.973 | Val Acc: 0.614 \n","Epoch 100/100 | Train Loss: 0.2104 | Val Loss: 0.9894 | Train Acc: 0.975 | Val Acc: 0.612 \n","Subject 8 FINAL BEST ACC: 70.96%\n","\n","Processing SUBJECT: 9\n","Epoch 1/100 | Train Loss: 5.7385 | Val Loss: 1.4822 | Train Acc: 0.264 | Val Acc: 0.283 (*) BEST\n","Epoch 4/100 | Train Loss: 1.3235 | Val Loss: 1.1228 | Train Acc: 0.411 | Val Acc: 0.463 (*) BEST\n","Epoch 5/100 | Train Loss: 1.2174 | Val Loss: 1.0595 | Train Acc: 0.445 | Val Acc: 0.594 (*) BEST\n","Epoch 8/100 | Train Loss: 1.0133 | Val Loss: 1.0655 | Train Acc: 0.580 | Val Acc: 0.675 (*) BEST\n","Epoch 10/100 | Train Loss: 0.9434 | Val Loss: 0.9850 | Train Acc: 0.614 | Val Acc: 0.671 \n","Epoch 13/100 | Train Loss: 0.8849 | Val Loss: 0.8607 | Train Acc: 0.655 | Val Acc: 0.789 (*) BEST\n","Epoch 20/100 | Train Loss: 0.6585 | Val Loss: 0.6932 | Train Acc: 0.749 | Val Acc: 0.671 \n","Epoch 21/100 | Train Loss: 0.5729 | Val Loss: 0.7270 | Train Acc: 0.820 | Val Acc: 0.811 (*) BEST\n","Epoch 26/100 | Train Loss: 0.5055 | Val Loss: 0.5830 | Train Acc: 0.825 | Val Acc: 0.825 (*) BEST\n","Epoch 30/100 | Train Loss: 0.4112 | Val Loss: 0.8003 | Train Acc: 0.865 | Val Acc: 0.619 \n","Epoch 40/100 | Train Loss: 0.2738 | Val Loss: 0.6615 | Train Acc: 0.920 | Val Acc: 0.612 \n","Epoch 50/100 | Train Loss: 0.1353 | Val Loss: 0.6464 | Train Acc: 0.977 | Val Acc: 0.730 \n","Epoch 59/100 | Train Loss: 0.0944 | Val Loss: 0.5779 | Train Acc: 0.994 | Val Acc: 0.844 (*) BEST\n","Epoch 60/100 | Train Loss: 0.0869 | Val Loss: 0.5921 | Train Acc: 0.994 | Val Acc: 0.827 \n","Epoch 70/100 | Train Loss: 0.0649 | Val Loss: 0.5702 | Train Acc: 0.997 | Val Acc: 0.726 \n","Epoch 80/100 | Train Loss: 0.0565 | Val Loss: 0.6505 | Train Acc: 1.000 | Val Acc: 0.770 \n","Epoch 90/100 | Train Loss: 0.0483 | Val Loss: 0.6308 | Train Acc: 1.000 | Val Acc: 0.752 \n","Epoch 100/100 | Train Loss: 0.0472 | Val Loss: 0.6232 | Train Acc: 1.000 | Val Acc: 0.761 \n","Subject 9 FINAL BEST ACC: 84.38%\n","\n","Processing SUBJECT: 10\n","Epoch 1/100 | Train Loss: 6.7607 | Val Loss: 2.4691 | Train Acc: 0.241 | Val Acc: 0.125 (*) BEST\n","Epoch 2/100 | Train Loss: 1.8696 | Val Loss: 1.7228 | Train Acc: 0.283 | Val Acc: 0.173 (*) BEST\n","Epoch 3/100 | Train Loss: 1.4626 | Val Loss: 1.1804 | Train Acc: 0.317 | Val Acc: 0.333 (*) BEST\n","Epoch 4/100 | Train Loss: 1.3808 | Val Loss: 1.2077 | Train Acc: 0.354 | Val Acc: 0.379 (*) BEST\n","Epoch 6/100 | Train Loss: 1.1756 | Val Loss: 1.2122 | Train Acc: 0.478 | Val Acc: 0.480 (*) BEST\n","Epoch 7/100 | Train Loss: 1.0874 | Val Loss: 1.0569 | Train Acc: 0.548 | Val Acc: 0.586 (*) BEST\n","Epoch 10/100 | Train Loss: 0.9995 | Val Loss: 0.9490 | Train Acc: 0.591 | Val Acc: 0.480 \n","Epoch 15/100 | Train Loss: 0.8519 | Val Loss: 0.8764 | Train Acc: 0.718 | Val Acc: 0.627 (*) BEST\n","Epoch 17/100 | Train Loss: 0.7907 | Val Loss: 0.8220 | Train Acc: 0.712 | Val Acc: 0.726 (*) BEST\n","Epoch 20/100 | Train Loss: 0.8097 | Val Loss: 0.8513 | Train Acc: 0.704 | Val Acc: 0.528 \n","Epoch 30/100 | Train Loss: 0.5879 | Val Loss: 0.8641 | Train Acc: 0.810 | Val Acc: 0.654 \n","Epoch 37/100 | Train Loss: 0.4954 | Val Loss: 1.0059 | Train Acc: 0.856 | Val Acc: 0.785 (*) BEST\n","Epoch 40/100 | Train Loss: 0.4356 | Val Loss: 1.0084 | Train Acc: 0.875 | Val Acc: 0.551 \n","Epoch 50/100 | Train Loss: 0.3518 | Val Loss: 1.0237 | Train Acc: 0.914 | Val Acc: 0.551 \n","Epoch 60/100 | Train Loss: 0.3545 | Val Loss: 0.8898 | Train Acc: 0.894 | Val Acc: 0.726 \n","Epoch 70/100 | Train Loss: 0.2541 | Val Loss: 0.9053 | Train Acc: 0.939 | Val Acc: 0.603 \n","Epoch 80/100 | Train Loss: 0.2111 | Val Loss: 1.0042 | Train Acc: 0.960 | Val Acc: 0.649 \n","Epoch 90/100 | Train Loss: 0.2037 | Val Loss: 1.0249 | Train Acc: 0.952 | Val Acc: 0.649 \n","Epoch 100/100 | Train Loss: 0.1905 | Val Loss: 1.0010 | Train Acc: 0.959 | Val Acc: 0.638 \n","Subject 10 FINAL BEST ACC: 78.49%\n","\n","Processing SUBJECT: 11\n","Epoch 1/100 | Train Loss: 7.5043 | Val Loss: 1.7811 | Train Acc: 0.258 | Val Acc: 0.125 (*) BEST\n","Epoch 3/100 | Train Loss: 1.4518 | Val Loss: 1.5446 | Train Acc: 0.314 | Val Acc: 0.208 (*) BEST\n","Epoch 4/100 | Train Loss: 1.3402 | Val Loss: 1.5539 | Train Acc: 0.358 | Val Acc: 0.320 (*) BEST\n","Epoch 5/100 | Train Loss: 1.4413 | Val Loss: 1.4123 | Train Acc: 0.335 | Val Acc: 0.342 (*) BEST\n","Epoch 10/100 | Train Loss: 1.2407 | Val Loss: 1.4393 | Train Acc: 0.435 | Val Acc: 0.283 \n","Epoch 14/100 | Train Loss: 1.1594 | Val Loss: 1.2670 | Train Acc: 0.513 | Val Acc: 0.537 (*) BEST\n","Epoch 20/100 | Train Loss: 1.1698 | Val Loss: 1.2611 | Train Acc: 0.505 | Val Acc: 0.537 \n","Epoch 26/100 | Train Loss: 1.0594 | Val Loss: 1.1590 | Train Acc: 0.571 | Val Acc: 0.544 (*) BEST\n","Epoch 30/100 | Train Loss: 0.9301 | Val Loss: 1.3462 | Train Acc: 0.639 | Val Acc: 0.259 \n","Epoch 34/100 | Train Loss: 0.8656 | Val Loss: 1.1076 | Train Acc: 0.667 | Val Acc: 0.559 (*) BEST\n","Epoch 36/100 | Train Loss: 0.8288 | Val Loss: 1.2072 | Train Acc: 0.695 | Val Acc: 0.561 (*) BEST\n","Epoch 40/100 | Train Loss: 0.7389 | Val Loss: 1.3469 | Train Acc: 0.767 | Val Acc: 0.355 \n","Epoch 50/100 | Train Loss: 0.6058 | Val Loss: 1.3700 | Train Acc: 0.802 | Val Acc: 0.336 \n","Epoch 60/100 | Train Loss: 0.4868 | Val Loss: 1.4151 | Train Acc: 0.873 | Val Acc: 0.300 \n","Epoch 70/100 | Train Loss: 0.4056 | Val Loss: 1.3630 | Train Acc: 0.914 | Val Acc: 0.518 \n","Epoch 80/100 | Train Loss: 0.3622 | Val Loss: 1.4423 | Train Acc: 0.945 | Val Acc: 0.500 \n","Epoch 90/100 | Train Loss: 0.3394 | Val Loss: 1.3298 | Train Acc: 0.948 | Val Acc: 0.460 \n","Epoch 100/100 | Train Loss: 0.3389 | Val Loss: 1.3749 | Train Acc: 0.964 | Val Acc: 0.460 \n","Subject 11 FINAL BEST ACC: 56.07%\n","\n","Processing SUBJECT: 12\n","Epoch 1/100 | Train Loss: 7.2876 | Val Loss: 1.5115 | Train Acc: 0.258 | Val Acc: 0.320 (*) BEST\n","Epoch 5/100 | Train Loss: 1.3645 | Val Loss: 1.3735 | Train Acc: 0.340 | Val Acc: 0.417 (*) BEST\n","Epoch 10/100 | Train Loss: 1.2819 | Val Loss: 1.5019 | Train Acc: 0.391 | Val Acc: 0.325 \n","Epoch 12/100 | Train Loss: 1.2270 | Val Loss: 1.3959 | Train Acc: 0.454 | Val Acc: 0.445 (*) BEST\n","Epoch 18/100 | Train Loss: 1.1509 | Val Loss: 1.4336 | Train Acc: 0.505 | Val Acc: 0.476 (*) BEST\n","Epoch 20/100 | Train Loss: 1.2090 | Val Loss: 1.7506 | Train Acc: 0.456 | Val Acc: 0.062 \n","Epoch 22/100 | Train Loss: 1.1296 | Val Loss: 1.3053 | Train Acc: 0.532 | Val Acc: 0.483 (*) BEST\n","Epoch 30/100 | Train Loss: 0.9762 | Val Loss: 1.5501 | Train Acc: 0.640 | Val Acc: 0.346 \n","Epoch 40/100 | Train Loss: 0.8672 | Val Loss: 1.2705 | Train Acc: 0.676 | Val Acc: 0.426 \n","Epoch 42/100 | Train Loss: 0.8224 | Val Loss: 1.3159 | Train Acc: 0.701 | Val Acc: 0.528 (*) BEST\n","Epoch 43/100 | Train Loss: 0.7700 | Val Loss: 1.3980 | Train Acc: 0.737 | Val Acc: 0.546 (*) BEST\n","Epoch 50/100 | Train Loss: 0.6539 | Val Loss: 1.3290 | Train Acc: 0.786 | Val Acc: 0.419 \n","Epoch 60/100 | Train Loss: 0.5748 | Val Loss: 1.4233 | Train Acc: 0.838 | Val Acc: 0.426 \n","Epoch 70/100 | Train Loss: 0.4573 | Val Loss: 1.3581 | Train Acc: 0.896 | Val Acc: 0.421 \n","Epoch 80/100 | Train Loss: 0.4349 | Val Loss: 1.2668 | Train Acc: 0.898 | Val Acc: 0.450 \n","Epoch 90/100 | Train Loss: 0.4130 | Val Loss: 1.3110 | Train Acc: 0.914 | Val Acc: 0.443 \n","Epoch 100/100 | Train Loss: 0.3903 | Val Loss: 1.2937 | Train Acc: 0.927 | Val Acc: 0.447 \n","Subject 12 FINAL BEST ACC: 54.60%\n","\n","Processing SUBJECT: 13\n","Epoch 1/100 | Train Loss: 7.3702 | Val Loss: 1.5376 | Train Acc: 0.271 | Val Acc: 0.191 (*) BEST\n","Epoch 2/100 | Train Loss: 1.8902 | Val Loss: 1.7580 | Train Acc: 0.292 | Val Acc: 0.320 (*) BEST\n","Epoch 3/100 | Train Loss: 1.4792 | Val Loss: 1.4681 | Train Acc: 0.353 | Val Acc: 0.399 (*) BEST\n","Epoch 9/100 | Train Loss: 1.0580 | Val Loss: 1.3382 | Train Acc: 0.556 | Val Acc: 0.417 (*) BEST\n","Epoch 10/100 | Train Loss: 1.1188 | Val Loss: 1.2962 | Train Acc: 0.540 | Val Acc: 0.417 \n","Epoch 12/100 | Train Loss: 1.0013 | Val Loss: 1.1943 | Train Acc: 0.599 | Val Acc: 0.524 (*) BEST\n","Epoch 13/100 | Train Loss: 0.9530 | Val Loss: 1.3927 | Train Acc: 0.620 | Val Acc: 0.551 (*) BEST\n","Epoch 20/100 | Train Loss: 0.9368 | Val Loss: 1.4384 | Train Acc: 0.609 | Val Acc: 0.482 \n","Epoch 30/100 | Train Loss: 0.6480 | Val Loss: 1.6339 | Train Acc: 0.740 | Val Acc: 0.333 \n","Epoch 40/100 | Train Loss: 0.4706 | Val Loss: 1.6322 | Train Acc: 0.844 | Val Acc: 0.351 \n","Epoch 50/100 | Train Loss: 0.2883 | Val Loss: 1.8915 | Train Acc: 0.946 | Val Acc: 0.524 \n","Epoch 60/100 | Train Loss: 0.2413 | Val Loss: 1.8663 | Train Acc: 0.952 | Val Acc: 0.509 \n","Epoch 70/100 | Train Loss: 0.1962 | Val Loss: 1.5835 | Train Acc: 0.977 | Val Acc: 0.524 \n","Epoch 80/100 | Train Loss: 0.1545 | Val Loss: 1.7498 | Train Acc: 0.983 | Val Acc: 0.502 \n","Epoch 90/100 | Train Loss: 0.1380 | Val Loss: 1.8459 | Train Acc: 0.994 | Val Acc: 0.524 \n","Epoch 100/100 | Train Loss: 0.1326 | Val Loss: 1.7956 | Train Acc: 0.995 | Val Acc: 0.524 \n","Subject 13 FINAL BEST ACC: 55.15%\n","\n","Processing SUBJECT: 14\n","Epoch 1/100 | Train Loss: 10.0631 | Val Loss: 2.0717 | Train Acc: 0.255 | Val Acc: 0.101 (*) BEST\n","Epoch 2/100 | Train Loss: 1.9461 | Val Loss: 1.8879 | Train Acc: 0.269 | Val Acc: 0.112 (*) BEST\n","Epoch 3/100 | Train Loss: 1.5054 | Val Loss: 1.3989 | Train Acc: 0.312 | Val Acc: 0.184 (*) BEST\n","Epoch 6/100 | Train Loss: 1.3551 | Val Loss: 1.3250 | Train Acc: 0.367 | Val Acc: 0.235 (*) BEST\n","Epoch 7/100 | Train Loss: 1.2519 | Val Loss: 1.3716 | Train Acc: 0.440 | Val Acc: 0.285 (*) BEST\n","Epoch 9/100 | Train Loss: 1.1946 | Val Loss: 1.2549 | Train Acc: 0.463 | Val Acc: 0.476 (*) BEST\n","Epoch 10/100 | Train Loss: 1.1986 | Val Loss: 1.3193 | Train Acc: 0.476 | Val Acc: 0.252 \n","Epoch 12/100 | Train Loss: 1.1458 | Val Loss: 1.3762 | Train Acc: 0.496 | Val Acc: 0.498 (*) BEST\n","Epoch 20/100 | Train Loss: 1.0388 | Val Loss: 1.7417 | Train Acc: 0.572 | Val Acc: 0.369 \n","Epoch 30/100 | Train Loss: 0.9066 | Val Loss: 1.3349 | Train Acc: 0.621 | Val Acc: 0.513 (*) BEST\n","Epoch 34/100 | Train Loss: 0.7499 | Val Loss: 1.0374 | Train Acc: 0.727 | Val Acc: 0.574 (*) BEST\n","Epoch 40/100 | Train Loss: 0.6343 | Val Loss: 0.9977 | Train Acc: 0.773 | Val Acc: 0.535 \n","Epoch 50/100 | Train Loss: 0.4912 | Val Loss: 1.3264 | Train Acc: 0.839 | Val Acc: 0.494 \n","Epoch 54/100 | Train Loss: 0.4153 | Val Loss: 1.1178 | Train Acc: 0.879 | Val Acc: 0.577 (*) BEST\n","Epoch 56/100 | Train Loss: 0.4625 | Val Loss: 0.9640 | Train Acc: 0.851 | Val Acc: 0.590 (*) BEST\n","Epoch 60/100 | Train Loss: 0.3746 | Val Loss: 1.0092 | Train Acc: 0.895 | Val Acc: 0.568 \n","Epoch 62/100 | Train Loss: 0.3816 | Val Loss: 0.8560 | Train Acc: 0.889 | Val Acc: 0.625 (*) BEST\n","Epoch 69/100 | Train Loss: 0.3722 | Val Loss: 1.0014 | Train Acc: 0.876 | Val Acc: 0.631 (*) BEST\n","Epoch 70/100 | Train Loss: 0.3338 | Val Loss: 0.9461 | Train Acc: 0.904 | Val Acc: 0.601 \n","Epoch 76/100 | Train Loss: 0.3143 | Val Loss: 0.8285 | Train Acc: 0.905 | Val Acc: 0.638 (*) BEST\n","Epoch 79/100 | Train Loss: 0.2997 | Val Loss: 0.9774 | Train Acc: 0.915 | Val Acc: 0.664 (*) BEST\n","Epoch 80/100 | Train Loss: 0.3146 | Val Loss: 1.0015 | Train Acc: 0.907 | Val Acc: 0.649 \n","Epoch 90/100 | Train Loss: 0.2768 | Val Loss: 0.9283 | Train Acc: 0.927 | Val Acc: 0.660 \n","Epoch 100/100 | Train Loss: 0.2826 | Val Loss: 0.9268 | Train Acc: 0.919 | Val Acc: 0.638 \n","Subject 14 FINAL BEST ACC: 66.36%\n","\n","Processing SUBJECT: 15\n","Epoch 1/100 | Train Loss: 7.3602 | Val Loss: 1.5571 | Train Acc: 0.266 | Val Acc: 0.320 (*) BEST\n","Epoch 2/100 | Train Loss: 1.4281 | Val Loss: 1.3576 | Train Acc: 0.340 | Val Acc: 0.382 (*) BEST\n","Epoch 3/100 | Train Loss: 1.1895 | Val Loss: 1.3328 | Train Acc: 0.488 | Val Acc: 0.493 (*) BEST\n","Epoch 4/100 | Train Loss: 1.1219 | Val Loss: 1.2166 | Train Acc: 0.530 | Val Acc: 0.656 (*) BEST\n","Epoch 7/100 | Train Loss: 0.8306 | Val Loss: 0.7369 | Train Acc: 0.720 | Val Acc: 0.699 (*) BEST\n","Epoch 8/100 | Train Loss: 0.7745 | Val Loss: 0.6904 | Train Acc: 0.729 | Val Acc: 0.877 (*) BEST\n","Epoch 10/100 | Train Loss: 0.6826 | Val Loss: 0.9285 | Train Acc: 0.779 | Val Acc: 0.612 \n","Epoch 20/100 | Train Loss: 0.3197 | Val Loss: 0.5899 | Train Acc: 0.908 | Val Acc: 0.812 \n","Epoch 22/100 | Train Loss: 0.2849 | Val Loss: 0.4407 | Train Acc: 0.924 | Val Acc: 0.886 (*) BEST\n","Epoch 24/100 | Train Loss: 0.2111 | Val Loss: 0.3977 | Train Acc: 0.959 | Val Acc: 0.919 (*) BEST\n","Epoch 30/100 | Train Loss: 0.1939 | Val Loss: 0.4983 | Train Acc: 0.947 | Val Acc: 0.871 \n","Epoch 40/100 | Train Loss: 0.0787 | Val Loss: 0.3317 | Train Acc: 0.997 | Val Acc: 0.886 \n","Epoch 45/100 | Train Loss: 0.0644 | Val Loss: 0.3437 | Train Acc: 0.997 | Val Acc: 0.949 (*) BEST\n","Epoch 50/100 | Train Loss: 0.0453 | Val Loss: 0.3298 | Train Acc: 0.999 | Val Acc: 0.892 \n","Epoch 60/100 | Train Loss: 0.0381 | Val Loss: 0.3328 | Train Acc: 0.999 | Val Acc: 0.814 \n","Epoch 70/100 | Train Loss: 0.0270 | Val Loss: 0.3216 | Train Acc: 1.000 | Val Acc: 0.877 \n","Epoch 80/100 | Train Loss: 0.0228 | Val Loss: 0.3141 | Train Acc: 1.000 | Val Acc: 0.886 \n","Epoch 90/100 | Train Loss: 0.0217 | Val Loss: 0.3212 | Train Acc: 1.000 | Val Acc: 0.886 \n","Epoch 100/100 | Train Loss: 0.0220 | Val Loss: 0.3197 | Train Acc: 1.000 | Val Acc: 0.886 \n","Subject 15 FINAL BEST ACC: 94.85%\n","\n","==================================================\n","FINAL RESULTS SUMMARY\n","==================================================\n","Subjects: 15 | Average Accuracy: 72.01% | Std: 12.03\n","Accuracies List: [61.95, 78.12, 77.76, 80.15, 63.05, 70.22, 88.05, 70.96, 84.38, 78.49, 56.07, 54.6, 55.15, 66.36, 94.85]\n"]}],"source":["all_subject_accuracies = []\n","\n","for subject_id in subjects:\n","    print(f\"\\nProcessing SUBJECT: {subject_id}\")\n","    \n","    # --- Data Split by Trials ---\n","    sub_df = dataset.info[dataset.info['subject_id'] == subject_id]\n","    all_trials = list(range(1, 25))\n","    random.seed(42)\n","    test_trials = random.sample(all_trials, 5)\n","    train_trials = [t for t in all_trials if t not in test_trials]\n","\n","    train_indices = sub_df[sub_df['trial_id'].isin(train_trials)].index.tolist()\n","    test_indices = sub_df[sub_df['trial_id'].isin(test_trials)].index.tolist()\n","\n","    train_set = Subset(dataset, train_indices)\n","    test_set = Subset(dataset, test_indices)\n","\n","    # --- Sampler for Class Imbalance ---\n","    y_train_indices = train_set.indices\n","    raw_labels = dataset.info.iloc[y_train_indices]['emotion'].values\n","    class_counts = np.bincount(raw_labels)\n","    class_weights = 1. / class_counts\n","    sample_weights = [class_weights[y] for y in raw_labels]\n","\n","    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","    train_loader = DataLoader(train_set, batch_size=64, sampler=sampler, num_workers=0)\n","    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=0)\n","\n","    # --- Model ---\n","    model = CCNN(\n","        num_classes=4,\n","        in_channels=5,        \n","        grid_size=(9, 9),     \n","        dropout=0.1\n","    ).to(device)\n","    model.apply(weights_init)\n","\n","    # --- Criterion & Optimizer ---\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    scheduler = CosineAnnealingLR(optimizer, T_max=100)\n","\n","    epochs = 100\n","    best_acc = 0.0\n","\n","    # --- Training Loop ---\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss_sum = 0\n","        correct = 0\n","        total = 0\n","\n","        for batch in train_loader:\n","            x, y = batch\n","            x, y = x.to(device), y.to(device)\n","\n","            optimizer.zero_grad()\n","            out = model(x)\n","            loss = criterion(out, y)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss_sum += loss.item()\n","            preds = out.argmax(dim=1)\n","            correct += (preds == y).sum().item()\n","            total += y.size(0)\n","\n","        avg_train_loss = train_loss_sum / len(train_loader)\n","        train_acc = correct / total\n","\n","        val_loss, val_acc = evaluate(model, test_loader, criterion)\n","        scheduler.step()\n","\n","        is_best = False\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            is_best = True\n","\n","        if is_best or (epoch + 1) % 10 == 0:\n","            status = \"(*) BEST\" if is_best else \"\"\n","            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f} {status}\")\n","\n","    all_subject_accuracies.append(best_acc)\n","    print(f\"Subject {subject_id} FINAL BEST ACC: {best_acc*100:.2f}%\")\n","\n","# --- Final Summary ---\n","print(\"\\n\" + \"=\"*50)\n","print(\"FINAL RESULTS SUMMARY\")\n","print(\"=\"*50)\n","final_avg_acc = np.mean(all_subject_accuracies)\n","final_std_acc = np.std(all_subject_accuracies)\n","print(f\"Subjects: {len(subjects)} | Average Accuracy: {final_avg_acc*100:.2f}% | Std: {final_std_acc*100:.2f}\")\n","print(f\"Accuracies List: {[round(x*100,2) for x in all_subject_accuracies]}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":218098,"sourceId":472319,"sourceType":"datasetVersion"}],"dockerImageVersionId":31193,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":2397.521756,"end_time":"2025-12-11T14:25:42.891439","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-11T13:45:45.369683","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}